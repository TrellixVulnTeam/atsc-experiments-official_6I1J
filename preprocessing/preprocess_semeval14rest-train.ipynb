{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocess_semeval14rest-train.ipynb","provenance":[{"file_id":"13Uuiig-8uZ_Bkg6NssQEOLujDkx4-yJ0","timestamp":1618494402410},{"file_id":"1HZRcbuLT7dKHVL_c5AXMj8cpXNUQz8Cx","timestamp":1618482437523},{"file_id":"10uitUAMMugkT4GzWH8-Fym8W-jGtkt1-","timestamp":1618481070596},{"file_id":"17vlkZFBPb3QsvbWkBLlDQG_QeqO-JZdm","timestamp":1618473918711},{"file_id":"1AT_0GiUm-x0jiLImp6kBPj2bJliUU7u9","timestamp":1612030190493}],"collapsed_sections":["h_WVE4pSNbd8","FK6Qt7kHWcwu","TA33P7z7pJ26","Yhf5gFid8__f","z8m9Y4Idr9Sa","GH_UWphkOcPU","cpCOtYGA0OQd","Iu9troUx3voZ","zY4NaEVH1Dhi","TEqIzsVi1HC2","7NvhTGvw1t4o","p4i-GN5Q1KlZ","ZOo0i09X1NXw","yplmfqOM2RsR","nViY_gpo2PJU"],"authorship_tag":"ABX9TyOyrSocNQx7fy5fL9Bz+UWC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TF99dpCJYsr","executionInfo":{"status":"ok","timestamp":1624894161143,"user_tz":-120,"elapsed":365,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"84bbf98f-410b-4f6b-cb4f-29d0afaaf31b"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"source":["TODO: adjust the following paths"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#data_path = \".../Data/SEMEVAL-14/Restaurants_Train.xml\"\n","#output_path = \".../Data/Final/SEMEVAL-14-REST/\"\n","#aspect_path = \".../preprocessing/aspect_positions/\"\n","#split_path = \".../preprocessing/split_indices/\""]},{"cell_type":"markdown","metadata":{"id":"D3r8d-AzWGcf"},"source":["# Data Import"]},{"cell_type":"code","metadata":{"id":"1HsS1-jUzDZp","executionInfo":{"status":"ok","timestamp":1624894161144,"user_tz":-120,"elapsed":10,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["import pandas as pd\n","import xml.etree.ElementTree as ET"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"12vjxMVvzMR2","executionInfo":{"status":"ok","timestamp":1624894161499,"user_tz":-120,"elapsed":362,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["parsedXML = ET.parse(data_path)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"5n6BloJzkKq7","executionInfo":{"status":"ok","timestamp":1624894161500,"user_tz":-120,"elapsed":7,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["aspect_number = 10"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"P07rAjP_lNXG","executionInfo":{"status":"ok","timestamp":1624894185612,"user_tz":-120,"elapsed":24117,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["dfcols = ['id','text']\n","for ii in range(1,aspect_number):\n","    dfcols.append(\"aspect_term_{}\".format(ii))\n","    dfcols.append(\"aspect_polarity_{}\".format(ii))\n","    dfcols.append(\"aspect_from_{}\".format(ii))\n","    dfcols.append(\"aspect_to_{}\".format(ii))          \n","df = pd.DataFrame(columns=dfcols)\n","\n","for sentence in parsedXML.getroot():\n","    id = sentence.attrib.get('id')\n","    text = sentence.find('text').text\n","    line = [id,text]\n","\n","    for asp in sentence.iter('aspectTerm'):\n","        term = asp.attrib.get(\"term\")\n","        pol = asp.attrib.get(\"polarity\")\n","        a_from = asp.attrib.get(\"from\")\n","        a_to = asp.attrib.get(\"to\")\n","\n","        line += [term, pol, a_from, a_to]\n","\n","    if len(line) < len(dfcols):\n","        pads = [None] * (len(dfcols)-len(line))\n","        line += pads\n","    \n","    df = df.append(pd.Series(line, index=dfcols), ignore_index=True)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nsuk3xIs5UUE","executionInfo":{"status":"ok","timestamp":1624894185614,"user_tz":-120,"elapsed":40,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"0ad9583c-853e-4b57-9ae3-8b097c11ab0d"},"source":["df"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>aspect_term_1</th>\n","      <th>aspect_polarity_1</th>\n","      <th>aspect_from_1</th>\n","      <th>aspect_to_1</th>\n","      <th>aspect_term_2</th>\n","      <th>aspect_polarity_2</th>\n","      <th>aspect_from_2</th>\n","      <th>aspect_to_2</th>\n","      <th>aspect_term_3</th>\n","      <th>aspect_polarity_3</th>\n","      <th>aspect_from_3</th>\n","      <th>aspect_to_3</th>\n","      <th>aspect_term_4</th>\n","      <th>aspect_polarity_4</th>\n","      <th>aspect_from_4</th>\n","      <th>aspect_to_4</th>\n","      <th>aspect_term_5</th>\n","      <th>aspect_polarity_5</th>\n","      <th>aspect_from_5</th>\n","      <th>aspect_to_5</th>\n","      <th>aspect_term_6</th>\n","      <th>aspect_polarity_6</th>\n","      <th>aspect_from_6</th>\n","      <th>aspect_to_6</th>\n","      <th>aspect_term_7</th>\n","      <th>aspect_polarity_7</th>\n","      <th>aspect_from_7</th>\n","      <th>aspect_to_7</th>\n","      <th>aspect_term_8</th>\n","      <th>aspect_polarity_8</th>\n","      <th>aspect_from_8</th>\n","      <th>aspect_to_8</th>\n","      <th>aspect_term_9</th>\n","      <th>aspect_polarity_9</th>\n","      <th>aspect_from_9</th>\n","      <th>aspect_to_9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3121</td>\n","      <td>But the staff was so horrible to us.</td>\n","      <td>staff</td>\n","      <td>negative</td>\n","      <td>8</td>\n","      <td>13</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2777</td>\n","      <td>To be completely fair, the only redeeming fact...</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>57</td>\n","      <td>61</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1634</td>\n","      <td>The food is uniformly exceptional, with a very...</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>kitchen</td>\n","      <td>positive</td>\n","      <td>55</td>\n","      <td>62</td>\n","      <td>menu</td>\n","      <td>neutral</td>\n","      <td>141</td>\n","      <td>145</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2534</td>\n","      <td>Where Gabriela personaly greets you and recomm...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>583</td>\n","      <td>For those that go once and don't enjoy it, all...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3039</th>\n","      <td>1063</td>\n","      <td>But that is highly forgivable.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3040</th>\n","      <td>777</td>\n","      <td>From the appetizers we ate, the dim sum and ot...</td>\n","      <td>appetizers</td>\n","      <td>positive</td>\n","      <td>9</td>\n","      <td>19</td>\n","      <td>dim sum</td>\n","      <td>positive</td>\n","      <td>32</td>\n","      <td>39</td>\n","      <td>foods</td>\n","      <td>positive</td>\n","      <td>61</td>\n","      <td>66</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>103</td>\n","      <td>107</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3041</th>\n","      <td>875</td>\n","      <td>When we arrived at 6:00 PM, the restaurant was...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3042</th>\n","      <td>671</td>\n","      <td>Each table has a pot of boiling water sunken i...</td>\n","      <td>table</td>\n","      <td>neutral</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>pot of boiling water</td>\n","      <td>neutral</td>\n","      <td>17</td>\n","      <td>37</td>\n","      <td>meats</td>\n","      <td>neutral</td>\n","      <td>99</td>\n","      <td>104</td>\n","      <td>vegetables</td>\n","      <td>neutral</td>\n","      <td>114</td>\n","      <td>124</td>\n","      <td>rice</td>\n","      <td>neutral</td>\n","      <td>130</td>\n","      <td>134</td>\n","      <td>glass noodles</td>\n","      <td>neutral</td>\n","      <td>139</td>\n","      <td>152</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3043</th>\n","      <td>617</td>\n","      <td>I am going to the mid town location next.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3044 rows × 38 columns</p>\n","</div>"],"text/plain":["        id  ... aspect_to_9\n","0     3121  ...        None\n","1     2777  ...        None\n","2     1634  ...        None\n","3     2534  ...        None\n","4      583  ...        None\n","...    ...  ...         ...\n","3039  1063  ...        None\n","3040   777  ...        None\n","3041   875  ...        None\n","3042   671  ...        None\n","3043   617  ...        None\n","\n","[3044 rows x 38 columns]"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"863AbS67LrD2"},"source":["# Drop duplicates"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":619},"id":"16yC8XZHoisI","executionInfo":{"status":"ok","timestamp":1624894185617,"user_tz":-120,"elapsed":33,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"3b4ed9b9-0519-4636-eeaf-dbc34dede62c"},"source":["cols_wo_id = df.columns\n","cols_wo_id = cols_wo_id.drop(\"id\")\n","df[df.duplicated(cols_wo_id, keep=False)].sort_values(\"text\")"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>aspect_term_1</th>\n","      <th>aspect_polarity_1</th>\n","      <th>aspect_from_1</th>\n","      <th>aspect_to_1</th>\n","      <th>aspect_term_2</th>\n","      <th>aspect_polarity_2</th>\n","      <th>aspect_from_2</th>\n","      <th>aspect_to_2</th>\n","      <th>aspect_term_3</th>\n","      <th>aspect_polarity_3</th>\n","      <th>aspect_from_3</th>\n","      <th>aspect_to_3</th>\n","      <th>aspect_term_4</th>\n","      <th>aspect_polarity_4</th>\n","      <th>aspect_from_4</th>\n","      <th>aspect_to_4</th>\n","      <th>aspect_term_5</th>\n","      <th>aspect_polarity_5</th>\n","      <th>aspect_from_5</th>\n","      <th>aspect_to_5</th>\n","      <th>aspect_term_6</th>\n","      <th>aspect_polarity_6</th>\n","      <th>aspect_from_6</th>\n","      <th>aspect_to_6</th>\n","      <th>aspect_term_7</th>\n","      <th>aspect_polarity_7</th>\n","      <th>aspect_from_7</th>\n","      <th>aspect_to_7</th>\n","      <th>aspect_term_8</th>\n","      <th>aspect_polarity_8</th>\n","      <th>aspect_from_8</th>\n","      <th>aspect_to_8</th>\n","      <th>aspect_term_9</th>\n","      <th>aspect_polarity_9</th>\n","      <th>aspect_from_9</th>\n","      <th>aspect_to_9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>273</th>\n","      <td>1976</td>\n","      <td>Finally!</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2463</th>\n","      <td>3063</td>\n","      <td>Finally!</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>449</th>\n","      <td>2149</td>\n","      <td>Good food.</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2022</th>\n","      <td>1691</td>\n","      <td>Good food.</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1404</th>\n","      <td>3196</td>\n","      <td>It was wonderful.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2835</th>\n","      <td>1613</td>\n","      <td>It was wonderful.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2195</th>\n","      <td>3201</td>\n","      <td>The service was excellent and the food was del...</td>\n","      <td>service</td>\n","      <td>positive</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>34</td>\n","      <td>38</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2746</th>\n","      <td>1952</td>\n","      <td>The service was excellent and the food was del...</td>\n","      <td>service</td>\n","      <td>positive</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>34</td>\n","      <td>38</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2044</th>\n","      <td>2662</td>\n","      <td>Unbelievable.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2900</th>\n","      <td>3200</td>\n","      <td>Unbelievable.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>679</th>\n","      <td>2575</td>\n","      <td>We will be back.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2903</th>\n","      <td>3428</td>\n","      <td>We will be back.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id  ... aspect_to_9\n","273   1976  ...        None\n","2463  3063  ...        None\n","449   2149  ...        None\n","2022  1691  ...        None\n","1404  3196  ...        None\n","2835  1613  ...        None\n","2195  3201  ...        None\n","2746  1952  ...        None\n","2044  2662  ...        None\n","2900  3200  ...        None\n","679   2575  ...        None\n","2903  3428  ...        None\n","\n","[12 rows x 38 columns]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"7VcO-JpTt4ev","executionInfo":{"status":"ok","timestamp":1624894185618,"user_tz":-120,"elapsed":30,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.drop_duplicates(cols_wo_id, ignore_index=True,inplace=True)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42Horu_479nq","executionInfo":{"status":"ok","timestamp":1624894185619,"user_tz":-120,"elapsed":29,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"00a3f40c-f237-459a-a858-192f1883770b"},"source":["text_counts = df.text.value_counts()\n","text_counts[:10]"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["I really liked the noodle dishes at Rice Avenue compared to their Green Curry dish.                                                                                      1\n","You should pass on the calamari.                                                                                                                                         1\n","Went there with my wife and we had to wait for a table even though you could see there many that were empty with not reservation sigh on them.                           1\n","Amma has the worst value for money I have experienced in NYC over the past 2 years.                                                                                      1\n","Frites were delicious if a bit on the thick side.                                                                                                                        1\n","IT is the best deal in town for a Monday night dinner at a fine restaurant.                                                                                              1\n","I have been a longtime fan of Holy Basil in the East Village, and while I do believe their food has slightly slipped in quality, I have been hesitant to be disloyal.    1\n","The service is outstanding and my crab-cake eggs benedict could not have been better.                                                                                    1\n","Went there for an office lunch.                                                                                                                                          1\n","The prices cannot be beat for the quality, quantity, freshness and taste.                                                                                                1\n","Name: text, dtype: int64"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSxXtAGIO7ID","executionInfo":{"status":"ok","timestamp":1624894185621,"user_tz":-120,"elapsed":25,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"d28eee86-2479-4cad-fb74-fcd1633cca30"},"source":["len(df)"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3038"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"k45Zoj6iWMcq"},"source":["# First Descriptive Analysis\n"]},{"cell_type":"markdown","metadata":{"id":"gQkriKTZKlcm"},"source":["## Aspects per sentence"]},{"cell_type":"code","metadata":{"id":"fNv56kkP3OKP","executionInfo":{"status":"ok","timestamp":1624894035080,"user_tz":-120,"elapsed":32,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["pol_cols = [\"aspect_polarity_\"+str(ii) for ii in range(1,aspect_number)]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ks804oRfuKxd","executionInfo":{"status":"ok","timestamp":1624894035081,"user_tz":-120,"elapsed":32,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"b512eb58-357e-4a0e-81a3-597b2ee1942e"},"source":["prev = 0\n","total_asp = 0\n","for no, col in enumerate(pol_cols):\n","    \n","    if col != \"aspect_polarity_1\":\n","        print(\"sentences with exactly \", no, \"aspects:\", prev - sum(df[col].value_counts()))\n","        total_asp += no * (prev - sum(df[col].value_counts()))\n","\n","    if col == \"aspect_polarity_\"+str(aspect_number-1):\n","        print(\"sentences with exactly \", no+1, \"aspects:\", sum(df[col].value_counts()))\n","        total_asp += (no+1) * sum(df[col].value_counts())\n","\n","    prev = sum(df[col].value_counts())\n","\n","print(\"total no of aspects: \", total_asp)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["sentences with exactly  1 aspects: 1023\n","sentences with exactly  2 aspects: 570\n","sentences with exactly  3 aspects: 270\n","sentences with exactly  4 aspects: 105\n","sentences with exactly  5 aspects: 29\n","sentences with exactly  6 aspects: 15\n","sentences with exactly  7 aspects: 5\n","sentences with exactly  8 aspects: 3\n","sentences with exactly  9 aspects: 1\n","total no of aspects:  3696\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h_WVE4pSNbd8"},"source":["## Sentiment Frequency"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xitO9zfJUBWD","executionInfo":{"status":"ok","timestamp":1624894035082,"user_tz":-120,"elapsed":28,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"5ab8e88d-9de6-447a-8137-07e5eb80ed45"},"source":["df_pol = df.loc[:,pol_cols]\n","df_pol_counts = df_pol.apply(pd.Series.value_counts)\n","df_pol_counts.sum(axis=1)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["conflict      91.0\n","negative     807.0\n","neutral      637.0\n","positive    2161.0\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oIhdlntE0lpQ","executionInfo":{"status":"ok","timestamp":1624894035083,"user_tz":-120,"elapsed":26,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"cfaf3aa9-8a89-4fd7-d418-ed580f10b634"},"source":["sum(df_pol_counts.sum(axis=1))"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3696.0"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"FK6Qt7kHWcwu"},"source":["## Sentences with more than one aspect"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0VOQtHlOdLy","executionInfo":{"status":"ok","timestamp":1624894035084,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"3706feb0-2dc8-4452-87f3-26cb7c732cb8"},"source":["multi_counter = 0\n","for line in df.index:\n","    sentiment_list = []\n","    for col in pol_cols:\n","        if df.loc[line,col] != None:\n","            sentiment_list += [df.loc[line,col]]\n","    if len(set(sentiment_list)) > 1:\n","        multi_counter += 1\n","multi_counter"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["356"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"TA33P7z7pJ26"},"source":["# Remove \"conflict\""]},{"cell_type":"code","metadata":{"id":"PMYoki_owON1","executionInfo":{"status":"ok","timestamp":1624894035692,"user_tz":-120,"elapsed":630,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["for line in range(len(df)):\n","    for col in pol_cols:\n","        if df.loc[line,col] == \"conflict\":\n","            df.loc[line,col] = None\n","            number = col[-1:]\n","            df.loc[line,\"aspect_term_\"+str(number)] = None\n","            df.loc[line,\"aspect_to_\"+str(number)] = None\n","            df.loc[line,\"aspect_from_\"+str(number)] = None"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"O7yBbHY4zFNV","executionInfo":{"status":"ok","timestamp":1624894035693,"user_tz":-120,"elapsed":13,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"bf2ead4f-91bb-4d87-80aa-80382bf3643e"},"source":["df"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>aspect_term_1</th>\n","      <th>aspect_polarity_1</th>\n","      <th>aspect_from_1</th>\n","      <th>aspect_to_1</th>\n","      <th>aspect_term_2</th>\n","      <th>aspect_polarity_2</th>\n","      <th>aspect_from_2</th>\n","      <th>aspect_to_2</th>\n","      <th>aspect_term_3</th>\n","      <th>aspect_polarity_3</th>\n","      <th>aspect_from_3</th>\n","      <th>aspect_to_3</th>\n","      <th>aspect_term_4</th>\n","      <th>aspect_polarity_4</th>\n","      <th>aspect_from_4</th>\n","      <th>aspect_to_4</th>\n","      <th>aspect_term_5</th>\n","      <th>aspect_polarity_5</th>\n","      <th>aspect_from_5</th>\n","      <th>aspect_to_5</th>\n","      <th>aspect_term_6</th>\n","      <th>aspect_polarity_6</th>\n","      <th>aspect_from_6</th>\n","      <th>aspect_to_6</th>\n","      <th>aspect_term_7</th>\n","      <th>aspect_polarity_7</th>\n","      <th>aspect_from_7</th>\n","      <th>aspect_to_7</th>\n","      <th>aspect_term_8</th>\n","      <th>aspect_polarity_8</th>\n","      <th>aspect_from_8</th>\n","      <th>aspect_to_8</th>\n","      <th>aspect_term_9</th>\n","      <th>aspect_polarity_9</th>\n","      <th>aspect_from_9</th>\n","      <th>aspect_to_9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3121</td>\n","      <td>But the staff was so horrible to us.</td>\n","      <td>staff</td>\n","      <td>negative</td>\n","      <td>8</td>\n","      <td>13</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2777</td>\n","      <td>To be completely fair, the only redeeming fact...</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>57</td>\n","      <td>61</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1634</td>\n","      <td>The food is uniformly exceptional, with a very...</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>kitchen</td>\n","      <td>positive</td>\n","      <td>55</td>\n","      <td>62</td>\n","      <td>menu</td>\n","      <td>neutral</td>\n","      <td>141</td>\n","      <td>145</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2534</td>\n","      <td>Where Gabriela personaly greets you and recomm...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>583</td>\n","      <td>For those that go once and don't enjoy it, all...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3033</th>\n","      <td>1063</td>\n","      <td>But that is highly forgivable.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3034</th>\n","      <td>777</td>\n","      <td>From the appetizers we ate, the dim sum and ot...</td>\n","      <td>appetizers</td>\n","      <td>positive</td>\n","      <td>9</td>\n","      <td>19</td>\n","      <td>dim sum</td>\n","      <td>positive</td>\n","      <td>32</td>\n","      <td>39</td>\n","      <td>foods</td>\n","      <td>positive</td>\n","      <td>61</td>\n","      <td>66</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>103</td>\n","      <td>107</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3035</th>\n","      <td>875</td>\n","      <td>When we arrived at 6:00 PM, the restaurant was...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3036</th>\n","      <td>671</td>\n","      <td>Each table has a pot of boiling water sunken i...</td>\n","      <td>table</td>\n","      <td>neutral</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>pot of boiling water</td>\n","      <td>neutral</td>\n","      <td>17</td>\n","      <td>37</td>\n","      <td>meats</td>\n","      <td>neutral</td>\n","      <td>99</td>\n","      <td>104</td>\n","      <td>vegetables</td>\n","      <td>neutral</td>\n","      <td>114</td>\n","      <td>124</td>\n","      <td>rice</td>\n","      <td>neutral</td>\n","      <td>130</td>\n","      <td>134</td>\n","      <td>glass noodles</td>\n","      <td>neutral</td>\n","      <td>139</td>\n","      <td>152</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3037</th>\n","      <td>617</td>\n","      <td>I am going to the mid town location next.</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3038 rows × 38 columns</p>\n","</div>"],"text/plain":["        id  ... aspect_to_9\n","0     3121  ...        None\n","1     2777  ...        None\n","2     1634  ...        None\n","3     2534  ...        None\n","4      583  ...        None\n","...    ...  ...         ...\n","3033  1063  ...        None\n","3034   777  ...        None\n","3035   875  ...        None\n","3036   671  ...        None\n","3037   617  ...        None\n","\n","[3038 rows x 38 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"Yhf5gFid8__f"},"source":["# Check for wrong positions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nckKUb_U9BuI","executionInfo":{"status":"ok","timestamp":1624894036303,"user_tz":-120,"elapsed":619,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"d9bf8306-e788-48d9-b4eb-49174f5f57ad"},"source":["mistakes = []\n","for ii in range(len(df)):\n","    for xx in range(1,aspect_number):\n","        asp_col = \"aspect_term_\"+str(xx)\n","        from_col = \"aspect_from_\"+str(xx)\n","        to_col = \"aspect_to_\"+str(xx)\n","        actual_term = df.loc[ii,asp_col]\n","        if actual_term != None:\n","            pos_term = df.text[ii][int(df.loc[ii,from_col]):int(df.loc[ii,to_col])]\n","            if actual_term != pos_term:\n","                mistakes += [ii]\n","                print(actual_term, pos_term)\n","mistakes"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"z8m9Y4Idr9Sa"},"source":["# Check for wrong aspect terms"]},{"cell_type":"code","metadata":{"id":"EB2miqWZnx_b","executionInfo":{"status":"ok","timestamp":1624894037014,"user_tz":-120,"elapsed":714,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["import nltk"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OeQ1uqko757","executionInfo":{"status":"ok","timestamp":1624894037521,"user_tz":-120,"elapsed":510,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"3378d745-bf00-4c8e-b46b-3801787f11b2"},"source":["nltk.download('punkt')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiykKcbXnYXm","executionInfo":{"status":"ok","timestamp":1624894038741,"user_tz":-120,"elapsed":1226,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"c1fe7938-6b9b-40f7-cd08-2202e85c2672"},"source":["for ii in range(len(df)):\n","    tokens = nltk.word_tokenize(df.text[ii])\n","    for xx in range(1,aspect_number):\n","        actual_term = df.loc[ii,\"aspect_term_\"+str(xx)]\n","        if actual_term != None:\n","            for asp_part in nltk.word_tokenize(actual_term):\n","                if asp_part not in tokens and asp_part+\"-\" not in tokens:\n","                    print(ii,\"-\",xx,\":\",tokens)\n","                    print(actual_term, asp_part)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["5 - 2 : ['Not', 'only', 'was', 'the', 'food', 'outstanding', ',', 'but', 'the', 'little', \"'perks\", \"'\", 'were', 'great', '.']\n","perks perks\n","41 - 1 : ['this', 'little', 'place', 'has', 'a', 'cute', 'interior', 'decor', 'and', 'affordable', 'city', 'prices', '.']\n","interior deco deco\n","474 - 1 : ['Food-awesome', '.']\n","Food Food\n","601 - 2 : ['We', 'had', 'the', 'pot-stickers', 'which', 'were', 'great', 'and', 'a', 'tempura', 'dish', 'that', 'was', 'great', '.']\n","tempura dis dis\n","934 - 5 : ['I', 'had', 'a', 'terrific', 'meal', ',', 'and', 'our', 'server', 'guided', 'us', 'toward', 'a', 'very', 'nice', 'wine', 'in', 'our', 'price', 'range', ',', 'instead', 'of', 'allowing', 'us', 'to', 'purchase', 'a', 'similarly', 'priced', 'wine', 'that', 'was', \"n't\", 'as', 'good', '.']\n","price rang rang\n","997 - 2 : ['They', 'also', 'have', 'a', 'back', 'garden', 'open', 'in', 'the', 'summer', '-', 'cute', 'and', 'French', 'with', 'outdoor', 'seating', '-', 'what', 'more', 'could', 'you', 'ask', 'for', '?']\n","outdoor seatin seatin\n","1041 - 2 : ['Great', 'wine', 'list', ',', 'reasonably', 'priced.', '--', 'Sara']\n","priced priced\n","1110 - 1 : ['But', 'the', 'thing', 'that', 'my', 'wife', 'and', 'I', 'hated', 'was', 'it', 'was', 'so', 'loud', 'and', 'it', 'felt', 'like', \"'bar\", \"'\", 'or', \"'pub\", \"'\", '.']\n","bar bar\n","1110 - 2 : ['But', 'the', 'thing', 'that', 'my', 'wife', 'and', 'I', 'hated', 'was', 'it', 'was', 'so', 'loud', 'and', 'it', 'felt', 'like', \"'bar\", \"'\", 'or', \"'pub\", \"'\", '.']\n","pub pub\n","1312 - 3 : ['My', 'husband', 'said', 'the', 'portions', 'were', 'very', 'small', ',', 'but', 'if', 'my', 'main', 'course', 'was', 'good', 'to', 'eat', 'the', 'portion', 'would', \"'ve\", 'been', 'fine', 'for', 'me', '.']\n","main cours cours\n","1520 - 3 : ['Although', 'be', 'warned', 'their', 'dinner', 'menu', 'to', 'sit', 'and', 'take', 'out', 'prices', 'are', 'different', '.']\n","take ou ou\n","1602 - 1 : ['It', 'is', 'obvious', 'that', 'no', 'one', 'in', 'the', 'restaurant', 'has', 'any', 'idea', 'about', 'or', 'experience', 'with', 'Japanese', 'cuisine', '.']\n","Japanese cuisin cuisin\n","1774 - 1 : ['Make', 'sure', 'you', 'have', 'the', 'Spicy', 'Scallop', 'roll..', '.']\n","Spicy Scallop roll roll\n","2024 - 2 : ['The', 'pesto', 'pizza', 'was', 'excellent', ',', 'thin-crust', 'pizza', 'with', 'a', 'nice', 'amount', 'of', 'spicy', 'Italian', 'cheese', 'that', 'I', \"'d\", 'never', 'heard', 'of', 'before', '.']\n","Italian chees chees\n","2162 - 3 : ['Considering', 'their', 'price', 'of', '$', '6.25', 'for', 'lunch', 'special', ',', 'the', 'dish', 'was', 'ridiculously', 'small', '.']\n","lunch specia specia\n","2688 - 1 : ['The', \"'kamasutra\", \"'\", 'and', \"'bombay\", 'cosmopolitan', \"'\", 'are', 'excellent', 'and', 'will', 'have', 'you', 'tipsy', 'in', 'no', 'time', '.']\n","kamasutra kamasutra\n","2688 - 2 : ['The', \"'kamasutra\", \"'\", 'and', \"'bombay\", 'cosmopolitan', \"'\", 'are', 'excellent', 'and', 'will', 'have', 'you', 'tipsy', 'in', 'no', 'time', '.']\n","bombay cosmopolitan bombay\n","2749 - 3 : ['Good', 'atmosphere', ',', 'combination', 'of', 'all', 'the', 'hottest', 'music', 'dress', 'code', 'is', 'relatively', 'strict', 'except', 'on', 'Fridays', '.']\n","dress cod cod\n","2849 - 2 : ['I', 'really', 'like', 'both', 'the', 'scallops', 'and', 'the', 'mahi', 'mahi', '(', 'on', 'saffron', 'risotto-yum', '!', ')', '.']\n","mahi mahi (on saffron risotto risotto\n","2944 - 2 : ['Interesting', 'other', 'dishes', 'for', 'a', 'change', 'include', 'chicken', 'in', 'curry', 'sauce', 'and', 'salmon', 'caserole', '.']\n","chicken in curry sauc sauc\n","3031 - 3 : ['We', 'shared', 'a', 'bottle', 'of', 'sake', ',', 'an', 'order', 'of', 'edamames', ',', 'and', 'she', 'had', 'the', 'sushi', 'plate', 'while', 'I', 'had', 'the', 'sashimi', '.']\n","sushi plat plat\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Br3VnaFUH6g","executionInfo":{"status":"ok","timestamp":1624894038742,"user_tz":-120,"elapsed":25,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[41,\"aspect_term_1\"] = \"interior decor\"\n","df.loc[41,\"aspect_to_1\"] = str(int(df.loc[41,\"aspect_to_1\"])+1)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9LAkPH1U-0M","executionInfo":{"status":"ok","timestamp":1624894038742,"user_tz":-120,"elapsed":22,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[601,\"aspect_term_2\"] = \"tempura dish\"\n","df.loc[601,\"aspect_to_2\"] = str(int(df.loc[601,\"aspect_to_2\"])+1)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fidv-SMbVZGv","executionInfo":{"status":"ok","timestamp":1624894038743,"user_tz":-120,"elapsed":21,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[934,\"aspect_term_5\"] = \"price range\"\n","df.loc[934,\"aspect_to_5\"] = str(int(df.loc[934,\"aspect_to_5\"])+1)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXKZtp2_Vmbs","executionInfo":{"status":"ok","timestamp":1624894038744,"user_tz":-120,"elapsed":19,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[997,\"aspect_term_2\"] = \"outdoor seating\"\n","df.loc[997,\"aspect_to_2\"] = str(int(df.loc[997,\"aspect_to_2\"])+1)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"d-G_L5NiWFHH","executionInfo":{"status":"ok","timestamp":1624894038744,"user_tz":-120,"elapsed":18,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[1312,\"aspect_term_3\"] = \"main course\"\n","df.loc[1312,\"aspect_to_3\"] = str(int(df.loc[1312,\"aspect_to_3\"])+1)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"0G0NGFvdfj-Z","executionInfo":{"status":"ok","timestamp":1624894038745,"user_tz":-120,"elapsed":18,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[1520,\"aspect_term_3\"] = \"take out\"\n","df.loc[1520,\"aspect_to_3\"] = str(int(df.loc[1520,\"aspect_to_3\"])+1)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"GcKrgtcIf-22","executionInfo":{"status":"ok","timestamp":1624894038747,"user_tz":-120,"elapsed":20,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[1602,\"aspect_term_1\"] = \"Japanese cuisine\"\n","df.loc[1602,\"aspect_to_1\"] = str(int(df.loc[1602,\"aspect_to_1\"])+1)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"bgujKYtbgLr_","executionInfo":{"status":"ok","timestamp":1624894038747,"user_tz":-120,"elapsed":19,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[2024,\"aspect_term_2\"] = \"Italian cheese\"\n","df.loc[2024,\"aspect_to_2\"] = str(int(df.loc[2024,\"aspect_to_2\"])+1)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"QQ5MBXXagZFI","executionInfo":{"status":"ok","timestamp":1624894038747,"user_tz":-120,"elapsed":18,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[2162,\"aspect_term_3\"] = \"lunch special\"\n","df.loc[2162,\"aspect_to_3\"] = str(int(df.loc[2162,\"aspect_to_3\"])+1)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Nl3xrJhgjwx","executionInfo":{"status":"ok","timestamp":1624894038747,"user_tz":-120,"elapsed":18,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[2749,\"aspect_term_3\"] = \"dress code\"\n","df.loc[2749,\"aspect_to_3\"] = str(int(df.loc[2749,\"aspect_to_3\"])+1)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgIkKHBLhMH2","executionInfo":{"status":"ok","timestamp":1624894038749,"user_tz":-120,"elapsed":19,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[2944,\"aspect_term_2\"] = \"chicken in curry sauce\"\n","df.loc[2944,\"aspect_to_2\"] = str(int(df.loc[2944,\"aspect_to_2\"])+1)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"HEXJ-6fPhWD5","executionInfo":{"status":"ok","timestamp":1624894038749,"user_tz":-120,"elapsed":18,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["df.loc[3031,\"aspect_term_3\"] = \"sushi plate\"\n","df.loc[3031,\"aspect_to_3\"] = str(int(df.loc[3031,\"aspect_to_3\"])+1)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"zriVGFEQhiDK","executionInfo":{"status":"ok","timestamp":1624894038750,"user_tz":-120,"elapsed":19,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"180c0b7f-a541-4b22-d950-69568c7e3d05"},"source":["df.loc[2849,\"aspect_term_2\"]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'mahi mahi (on saffron risotto'"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"I4890gf_IfDW"},"source":["Re-check for wrong positions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbRs6QssIfDY","executionInfo":{"status":"ok","timestamp":1624894039165,"user_tz":-120,"elapsed":431,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"1d6c0b67-3345-4111-9f87-2462640179a6"},"source":["mistakes = []\n","for ii in range(len(df)):\n","    for xx in range(1,aspect_number):\n","        asp_col = \"aspect_term_\"+str(xx)\n","        from_col = \"aspect_from_\"+str(xx)\n","        to_col = \"aspect_to_\"+str(xx)\n","        actual_term = df.loc[ii,asp_col]\n","        if actual_term != None:\n","            pos_term = df.text[ii][int(df.loc[ii,from_col]):int(df.loc[ii,to_col])]\n","            if actual_term != pos_term:\n","                mistakes += [ii]\n","                print(actual_term, pos_term)\n","mistakes"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"ItbY02p9vXSV"},"source":["# Drop lines without aspects"]},{"cell_type":"code","metadata":{"id":"LSrHan4NrdS5","executionInfo":{"status":"ok","timestamp":1624894039165,"user_tz":-120,"elapsed":5,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["def pol_to_no(sentiment):\n","  \n","    if sentiment == \"positive\":\n","        pol = 1\n","    elif sentiment == \"negative\":\n","        pol = -1\n","    elif sentiment == \"neutral\":\n","        pol = 0\n","\n","    return pol"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"L4JGUeB79Tpw","executionInfo":{"status":"ok","timestamp":1624894039495,"user_tz":-120,"elapsed":334,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["all_pols = []\n","no_pol = []\n","for line in df.index:\n","    pols = []\n","    for col in pol_cols:\n","        if df.loc[line,col] != None:\n","            pols += [pol_to_no(df.loc[line,col])]\n","    if len(pols) > 0:\n","        all_pols += [pols]\n","    else:\n","        no_pol += [line]\n","\n","df_pol = pd.DataFrame(data=all_pols)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mzMGaTMKvfYY","executionInfo":{"status":"ok","timestamp":1624894039495,"user_tz":-120,"elapsed":11,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"627f8e03-525d-419d-8886-d5baaa668771"},"source":["df.drop(no_pol, axis=0, inplace=True)\n","df.reset_index(inplace=True, drop=True)\n","df"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>aspect_term_1</th>\n","      <th>aspect_polarity_1</th>\n","      <th>aspect_from_1</th>\n","      <th>aspect_to_1</th>\n","      <th>aspect_term_2</th>\n","      <th>aspect_polarity_2</th>\n","      <th>aspect_from_2</th>\n","      <th>aspect_to_2</th>\n","      <th>aspect_term_3</th>\n","      <th>aspect_polarity_3</th>\n","      <th>aspect_from_3</th>\n","      <th>aspect_to_3</th>\n","      <th>aspect_term_4</th>\n","      <th>aspect_polarity_4</th>\n","      <th>aspect_from_4</th>\n","      <th>aspect_to_4</th>\n","      <th>aspect_term_5</th>\n","      <th>aspect_polarity_5</th>\n","      <th>aspect_from_5</th>\n","      <th>aspect_to_5</th>\n","      <th>aspect_term_6</th>\n","      <th>aspect_polarity_6</th>\n","      <th>aspect_from_6</th>\n","      <th>aspect_to_6</th>\n","      <th>aspect_term_7</th>\n","      <th>aspect_polarity_7</th>\n","      <th>aspect_from_7</th>\n","      <th>aspect_to_7</th>\n","      <th>aspect_term_8</th>\n","      <th>aspect_polarity_8</th>\n","      <th>aspect_from_8</th>\n","      <th>aspect_to_8</th>\n","      <th>aspect_term_9</th>\n","      <th>aspect_polarity_9</th>\n","      <th>aspect_from_9</th>\n","      <th>aspect_to_9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3121</td>\n","      <td>But the staff was so horrible to us.</td>\n","      <td>staff</td>\n","      <td>negative</td>\n","      <td>8</td>\n","      <td>13</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2777</td>\n","      <td>To be completely fair, the only redeeming fact...</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>57</td>\n","      <td>61</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1634</td>\n","      <td>The food is uniformly exceptional, with a very...</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>kitchen</td>\n","      <td>positive</td>\n","      <td>55</td>\n","      <td>62</td>\n","      <td>menu</td>\n","      <td>neutral</td>\n","      <td>141</td>\n","      <td>145</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2846</td>\n","      <td>Not only was the food outstanding, but the lit...</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>17</td>\n","      <td>21</td>\n","      <td>perks</td>\n","      <td>positive</td>\n","      <td>51</td>\n","      <td>56</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1458</td>\n","      <td>Our agreed favorite is the orrechiete with sau...</td>\n","      <td>orrechiete with sausage and chicken</td>\n","      <td>positive</td>\n","      <td>27</td>\n","      <td>62</td>\n","      <td>waiters</td>\n","      <td>positive</td>\n","      <td>76</td>\n","      <td>83</td>\n","      <td>meats</td>\n","      <td>neutral</td>\n","      <td>152</td>\n","      <td>157</td>\n","      <td>dish</td>\n","      <td>neutral</td>\n","      <td>113</td>\n","      <td>117</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1973</th>\n","      <td>2378</td>\n","      <td>The service was typical short-order, dinner type.</td>\n","      <td>service</td>\n","      <td>neutral</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1974</th>\n","      <td>1027</td>\n","      <td>We shared a bottle of sake, an order of edamam...</td>\n","      <td>bottle of sake</td>\n","      <td>neutral</td>\n","      <td>12</td>\n","      <td>26</td>\n","      <td>edamames</td>\n","      <td>neutral</td>\n","      <td>40</td>\n","      <td>48</td>\n","      <td>sushi plate</td>\n","      <td>neutral</td>\n","      <td>66</td>\n","      <td>77</td>\n","      <td>sashimi</td>\n","      <td>neutral</td>\n","      <td>94</td>\n","      <td>101</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1975</th>\n","      <td>1735</td>\n","      <td>I can't believe people complain about no chees...</td>\n","      <td>cheese sticks</td>\n","      <td>neutral</td>\n","      <td>41</td>\n","      <td>54</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1976</th>\n","      <td>777</td>\n","      <td>From the appetizers we ate, the dim sum and ot...</td>\n","      <td>appetizers</td>\n","      <td>positive</td>\n","      <td>9</td>\n","      <td>19</td>\n","      <td>dim sum</td>\n","      <td>positive</td>\n","      <td>32</td>\n","      <td>39</td>\n","      <td>foods</td>\n","      <td>positive</td>\n","      <td>61</td>\n","      <td>66</td>\n","      <td>food</td>\n","      <td>positive</td>\n","      <td>103</td>\n","      <td>107</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1977</th>\n","      <td>671</td>\n","      <td>Each table has a pot of boiling water sunken i...</td>\n","      <td>table</td>\n","      <td>neutral</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>pot of boiling water</td>\n","      <td>neutral</td>\n","      <td>17</td>\n","      <td>37</td>\n","      <td>meats</td>\n","      <td>neutral</td>\n","      <td>99</td>\n","      <td>104</td>\n","      <td>vegetables</td>\n","      <td>neutral</td>\n","      <td>114</td>\n","      <td>124</td>\n","      <td>rice</td>\n","      <td>neutral</td>\n","      <td>130</td>\n","      <td>134</td>\n","      <td>glass noodles</td>\n","      <td>neutral</td>\n","      <td>139</td>\n","      <td>152</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1978 rows × 38 columns</p>\n","</div>"],"text/plain":["        id  ... aspect_to_9\n","0     3121  ...        None\n","1     2777  ...        None\n","2     1634  ...        None\n","3     2846  ...        None\n","4     1458  ...        None\n","...    ...  ...         ...\n","1973  2378  ...        None\n","1974  1027  ...        None\n","1975  1735  ...        None\n","1976   777  ...        None\n","1977   671  ...        None\n","\n","[1978 rows x 38 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"SO4Q-QgTOnQb"},"source":["# Descriptive Analysis\n"]},{"cell_type":"markdown","metadata":{"id":"u2F8QnbGOnQc"},"source":["## Aspects per sentence"]},{"cell_type":"code","metadata":{"id":"l7OlxZ0dOnQd","executionInfo":{"status":"ok","timestamp":1624894039496,"user_tz":-120,"elapsed":10,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}}},"source":["pol_cols = [\"aspect_polarity_\"+str(ii) for ii in range(1,aspect_number)]"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okzYLyljOnQe","executionInfo":{"status":"ok","timestamp":1624894039496,"user_tz":-120,"elapsed":10,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"d4cf537a-60a1-4af6-ace1-f731de589487"},"source":["prev = 0\n","total_asp = 0\n","for no, col in enumerate(pol_cols):\n","    \n","    if col != \"aspect_polarity_1\":\n","        print(\"sentences with exactly \", no, \"aspects:\", prev - sum(df[col].value_counts()))\n","        total_asp += no * (prev - sum(df[col].value_counts()))\n","\n","    if col == \"aspect_polarity_\"+str(aspect_number-1):\n","        print(\"sentences with exactly \", no+1, \"aspects:\", sum(df[col].value_counts()))\n","        total_asp += (no+1) * sum(df[col].value_counts())\n","\n","    prev = sum(df[col].value_counts())\n","\n","print(\"total no of aspects: \", total_asp)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["sentences with exactly  1 aspects: 966\n","sentences with exactly  2 aspects: 565\n","sentences with exactly  3 aspects: 262\n","sentences with exactly  4 aspects: 105\n","sentences with exactly  5 aspects: 29\n","sentences with exactly  6 aspects: 15\n","sentences with exactly  7 aspects: 5\n","sentences with exactly  8 aspects: 3\n","sentences with exactly  9 aspects: 1\n","total no of aspects:  3605\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ea4PdPbpOnQf"},"source":["## Sentiment Frequency"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bqr_mxyPOnQg","executionInfo":{"status":"ok","timestamp":1624894039894,"user_tz":-120,"elapsed":405,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"243e8195-b27a-4469-ded8-3095ebcfcf5e"},"source":["df_pol = df.loc[:,pol_cols]\n","df_pol_counts = df_pol.apply(pd.Series.value_counts)\n","df_pol_counts.sum(axis=1)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["negative     807.0\n","neutral      637.0\n","positive    2161.0\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZUrZfqLuOnQi","executionInfo":{"status":"ok","timestamp":1624894039896,"user_tz":-120,"elapsed":10,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"b2be5e5c-9cc8-49fa-bb99-d07778612bb2"},"source":["sum(df_pol_counts.sum(axis=1))"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3605.0"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"mD_lLexCOnQj"},"source":["## Sentences with more than one aspect"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rhQkAEw3OnQj","executionInfo":{"status":"ok","timestamp":1624894039897,"user_tz":-120,"elapsed":8,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"853c9f15-a708-43b5-8821-33765a90d732"},"source":["multi_counter = 0\n","for line in df.index:\n","    sentiment_list = []\n","    for col in pol_cols:\n","        if df.loc[line,col] != None:\n","            sentiment_list += [df.loc[line,col]]\n","    if len(set(sentiment_list)) > 1:\n","        multi_counter += 1\n","multi_counter"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["320"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"GH_UWphkOcPU"},"source":["# Train/Val Split"]},{"cell_type":"markdown","metadata":{"id":"BWuFOJpwMamc"},"source":["## In case of splitting for the first time"]},{"cell_type":"code","metadata":{"id":"_F3FyRLgw8N8"},"source":["#!pip install scikit-multilearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IWlHxREbvcq0"},"source":["#from skmultilearn.model_selection import IterativeStratification"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYnX_obr0G3c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623758659325,"user_tz":-120,"elapsed":13,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"5e455c69-1e76-4b22-8e7d-4a13f9845e5f"},"source":["'''\n","k_fold = IterativeStratification(n_splits=10, order=1)\n","\n","ii = 1\n","data_dict = {}\n","\n","for train, val in k_fold.split(df, df_pol):\n","\n","    if ii < 6:\n","        print(ii)\n","        print(len(train), len(val), len(train) + len(val))\n","        print(100*round(len(train)/(len(train) + len(val)),4), 100*round(len(val)/(len(train) + len(val)),4))\n","\n","        data_dict[\"train_\"+str(ii)] = df.loc[train]\n","        data_dict[\"val_\"+str(ii)] = df.loc[val]\n","\n","        with open(split_path+\"semeval_14_rest_train_\"+str(ii)+\".txt\", \"w\") as f:\n","            for ind in train:\n","                f.write(str(ind)+\"\\n\")\n","        with open(split_path+\"semeval_14_rest_val_\"+str(ii)+\".txt\", \"w\") as f:\n","            for ind in val:\n","               f.write(str(ind)+\"\\n\")\n","\n","        ii += 1\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nk_fold = IterativeStratification(n_splits=10, order=1)\\n\\nii = 1\\ndata_dict = {}\\n\\nfor train, val in k_fold.split(df, df_pol):\\n\\n    if ii < 6:\\n        print(ii)\\n        print(len(train), len(val), len(train) + len(val))\\n        print(100*round(len(train)/(len(train) + len(val)),4), 100*round(len(val)/(len(train) + len(val)),4))\\n\\n        data_dict[\"train_\"+str(ii)] = df.loc[train]\\n        data_dict[\"val_\"+str(ii)] = df.loc[val]\\n\\n        with open(\"/content/drive/My Drive/Masterarbeit/Data/preprocessing/split_indices/semeval_14_rest_train_\"+str(ii)+\".txt\", \"w\") as f:\\n            for ind in train:\\n                f.write(str(ind)+\"\\n\")\\n        with open(\"/content/drive/My Drive/Masterarbeit/Data/preprocessing/split_indices/semeval_14_rest_val_\"+str(ii)+\".txt\", \"w\") as f:\\n            for ind in val:\\n               f.write(str(ind)+\"\\n\")\\n\\n        ii += 1\\n'"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"mE-1i_NoMezJ"},"source":["## In case of reproducing a split"]},{"cell_type":"code","metadata":{"id":"JjahLIM9MmeY"},"source":["data_dict = {}\n","for ii in range(1,6):\n","    with open(split_path+\"semeval_14_rest_train_\"+str(ii)+\".txt\", \"r\") as f:\n","        mylist = f.read().splitlines()\n","    train = [int(x) for x in mylist]\n","    data_dict[\"train_\"+str(ii)] = df.loc[train]\n","\n","    with open(split_path+\"semeval_14_rest_val_\"+str(ii)+\".txt\", \"r\") as f:\n","        mylist = f.read().splitlines()\n","    val = [int(x) for x in mylist]\n","    data_dict[\"val_\"+str(ii)] = df.loc[val]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cpCOtYGA0OQd"},"source":["# Save as xml"]},{"cell_type":"code","metadata":{"id":"iYzlSnxhzl0N"},"source":["def xml_maker(df,aspect_number):\n","\n","    root = ET.Element('sentences')\n","\n","    for line in df.index:\n","        name = \"sentence\"\n","        entry = ET.SubElement(root, name)\n","        entry.set(\"id\", str(df[\"id\"][line]))\n","\n","        text_child = ET.SubElement(entry, \"text\")\n","        text_child.text = str(df[\"text\"][line])\n","\n","        asp_child = ET.SubElement(entry, \"aspectTerms\")\n","        for xx in range(1,aspect_number):\n","            if df.loc[line,\"aspect_term_\"+str(xx)] != None:\n","                asp_subchild = ET.SubElement(asp_child, \"aspectTerm\")\n","                asp_subchild.set(\"from\",str(df[\"aspect_from_\"+str(xx)][line]))\n","                asp_subchild.set(\"polarity\",str(df[\"aspect_polarity_\"+str(xx)][line]))\n","                asp_subchild.set(\"term\",str(df[\"aspect_term_\"+str(xx)][line]))\n","                asp_subchild.set(\"to\",str(df[\"aspect_to_\"+str(xx)][line]))\n","\n","    return ET.tostring(root)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZ-FU7HtPq1H"},"source":["for key,val in data_dict.items():\n","\n","    xml_data = xml_maker(val,aspect_number)\n","\n","    with open(output_path+key+\".xml\",\"w\") as f:\n","        f.write(xml_data.decode('utf-8'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iu9troUx3voZ"},"source":["# Create xml.seg"]},{"cell_type":"code","metadata":{"id":"UIXzzTPlRkwc"},"source":["def xml_seg_maker(df):\n","\n","    df_wo_id = df.drop(columns=\"id\", axis=1, inplace=False)\n","    df_wo_id.reset_index(drop=True, inplace=True)\n","    data_lines = []\n","    counter = {\"pos\": 0, \"neu\": 0, \"neg\": 0}\n","\n","    for ii in df_wo_id.index:\n","\n","        line = list(df_wo_id.loc[ii])\n","        o_text = line[0]\n","        aspects = [line[xx] for xx in range(1,len(df_wo_id.loc[0]),4) if line[xx] != None]\n","        pols = [line[xx] for xx in range(2,len(df_wo_id.loc[0]),4) if line[xx] != None]\n","\n","        for asp in range(len(aspects)):\n","            text = o_text.replace(aspects[asp],'$T$')\n","            pol = str(pol_to_no(pols[asp]))\n","\n","            if pol == \"1\":\n","                counter[\"pos\"] += 1\n","            elif pol == \"0\":\n","                counter[\"neu\"] += 1\n","            elif pol == \"-1\":\n","                counter[\"neg\"] += 1\n","\n","            data_lines += [text,aspects[asp],pol]\n","    \n","    return data_lines, counter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ND8pnKtwCLZL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619435584419,"user_tz":-120,"elapsed":7240,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"92722d90-3069-4435-8709-b1922a1a3b17"},"source":["for key,val in data_dict.items():\n","\n","    xml_seg_data, counter = xml_seg_maker(val)\n","    print(\"aspects in \", key, \":\", len(xml_seg_data)/3)\n","    print(key, \": sentiment counter: \", counter)\n","\n","    with open(output_path+key+\".xml.seg\",\"w\") as f:\n","        f.write('\\n'.join(xml_seg_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["aspects in  train_1 : 3236.0\n","train_1 : sentiment counter:  {'pos': 1943, 'neu': 572, 'neg': 721}\n","aspects in  val_1 : 369.0\n","val_1 : sentiment counter:  {'pos': 218, 'neu': 65, 'neg': 86}\n","aspects in  train_2 : 3241.0\n","train_2 : sentiment counter:  {'pos': 1944, 'neu': 571, 'neg': 726}\n","aspects in  val_2 : 364.0\n","val_2 : sentiment counter:  {'pos': 217, 'neu': 66, 'neg': 81}\n","aspects in  train_3 : 3258.0\n","train_3 : sentiment counter:  {'pos': 1930, 'neu': 581, 'neg': 747}\n","aspects in  val_3 : 347.0\n","val_3 : sentiment counter:  {'pos': 231, 'neu': 56, 'neg': 60}\n","aspects in  train_4 : 3250.0\n","train_4 : sentiment counter:  {'pos': 1965, 'neu': 577, 'neg': 708}\n","aspects in  val_4 : 355.0\n","val_4 : sentiment counter:  {'pos': 196, 'neu': 60, 'neg': 99}\n","aspects in  train_5 : 3244.0\n","train_5 : sentiment counter:  {'pos': 1943, 'neu': 570, 'neg': 731}\n","aspects in  val_5 : 361.0\n","val_5 : sentiment counter:  {'pos': 218, 'neu': 67, 'neg': 76}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zY4NaEVH1Dhi"},"source":["# Create BERT+txt"]},{"cell_type":"code","metadata":{"id":"7c_Zb3Lk1vUa"},"source":["asp_cols = [\"aspect_term_\"+str(ii) for ii in range(1,aspect_number)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kopkDBAmmkxV"},"source":["def sent_conv(sentiment):\n","\n","    if sentiment == \"positive\":\n","        return \"POS\"\n","    elif sentiment == \"negative\":\n","        return \"NEG\"\n","    elif sentiment == \"neutral\":\n","        return \"NEU\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8E6pSYzt08i"},"source":["def txt_maker(df):\n","\n","    data_lines = []\n","\n","    for line in df.index:\n","\n","        text = df.loc[line,\"text\"]        \n","        tokens = nltk.word_tokenize(text)\n","\n","        # correct tokens\n","        for no,tok in enumerate(tokens):\n","            if tok[-1:] == \"-\" and len(tok)>2:\n","                tokens[no] = tok[:-1]\n","            if tok[:1] == \"'\" and len(tok)>3:\n","                tokens[no] = tok[1:]\n","            if tok in [\"'\",\"(\",\")\"]:\n","                tokens.remove(tok)\n","\n","        # create aspect-polarity dict\n","        asp_sent_dict = {}\n","        max_asp_len = 0\n","        for col in range(len(asp_cols)):\n","            aspect = df.loc[line,asp_cols[col]]\n","            if aspect != None:\n","                asp_sent_dict[aspect] = sent_conv(df.loc[line,pol_cols[col]])\n","                if len(aspect.split()) > max_asp_len:\n","                    max_asp_len = len(aspect.split())\n","\n","\n","        label = \"\"\n","        # check for one-word-aspects\n","        for tok in tokens:\n","            if tok in asp_sent_dict.keys():\n","                label += tok + \"=T-\" + asp_sent_dict[tok] + \" \"\n","            else:\n","                label += tok + \"=O \"\n","        label = label[:-1]\n","\n","        # check for multi-word-aspects\n","        for ii in range(2,max_asp_len+1):\n","            for no,tok in enumerate(tokens):\n","                new_tok = \" \".join(tokens[no:no+ii])\n","                if new_tok in asp_sent_dict.keys():\n","                    new_pol = asp_sent_dict[new_tok]\n","                    old_label = \" \".join([tokens[no+xx]+\"=O\" for xx in range(ii) if no+xx < len(tokens)])\n","                    new_label = \" \".join([tokens[no+xx]+\"=T-\"+new_pol for xx in range(ii) if no+xx < len(tokens)])\n","                    label = label.replace(old_label, new_label)\n","  \n","        data_lines += [text+\"####\"+label]\n","\n","    return data_lines"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvTsu2IyupwT"},"source":["for key,val in data_dict.items():\n","\n","    txt_data = txt_maker(val)\n","\n","    with open(output_path+key+\".txt\",\"w\") as f:\n","        f.write('\\n'.join(txt_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p4i-GN5Q1KlZ"},"source":["# Create RGATjson"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCyhkwcKwClh","executionInfo":{"status":"ok","timestamp":1620722371840,"user_tz":-120,"elapsed":48329,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"fc60b43b-3da7-400f-ed38-ed24d73b5765"},"source":["!pip install stanza"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting stanza\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n","\r\u001b[K     |█▏                              | 10kB 14.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 13.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 112kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 143kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 163kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 184kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 204kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 215kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 225kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 235kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 245kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 266kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 276kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 4.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.41.1)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.8.1+cu101)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.12.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (56.1.0)\n","Installing collected packages: stanza\n","Successfully installed stanza-1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Le-5FSclw2rm"},"source":["import stanza\n","from more_itertools import locate\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hp6-9OkNwJ1e","executionInfo":{"status":"ok","timestamp":1620722589607,"user_tz":-120,"elapsed":263271,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"e76077c8-fcbe-4373-bcbf-593dc595dcf7"},"source":["stanza.download('en')\n","nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 20.2MB/s]                    \n","2021-05-11 08:39:38 INFO: Downloading default packages for language: en (English)...\n","Downloading http://nlp.stanford.edu/software/stanza/1.2.0/en/default.zip: 100%|██████████| 411M/411M [03:21<00:00, 2.04MB/s]\n","2021-05-11 08:43:11 INFO: Finished downloading models and saved to /root/stanza_resources.\n","2021-05-11 08:43:11 INFO: Loading these models for language: en (English):\n","========================\n","| Processor | Package  |\n","------------------------\n","| tokenize  | combined |\n","| pos       | combined |\n","| lemma     | combined |\n","| depparse  | combined |\n","========================\n","\n","2021-05-11 08:43:11 INFO: Use device: cpu\n","2021-05-11 08:43:11 INFO: Loading: tokenize\n","2021-05-11 08:43:11 INFO: Loading: pos\n","2021-05-11 08:43:12 INFO: Loading: lemma\n","2021-05-11 08:43:12 INFO: Loading: depparse\n","2021-05-11 08:43:12 INFO: Done loading processors!\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BvGzY7ydRUxU"},"source":["## in case of creating for the first time"]},{"cell_type":"code","metadata":{"id":"pu0faFFvVJOI"},"source":["data_1 = pd.concat([data_dict[\"train_1\"], data_dict[\"val_1\"]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILMTmvCG-sY6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620723549865,"user_tz":-120,"elapsed":960235,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"bea9e7fd-0cec-4182-e26b-912a5eb24812"},"source":["'''\n","def json_make_pos(df):\n","   \n","    manual_pos = {}\n","\n","    for ii in df.index:\n","        \n","        new_dict = {}\n","        text = df.loc[ii,\"text\"]\n","        tokens = [token.text for sentence in nlp(text).sentences for token in sentence.tokens]\n","        \n","        new_dict[\"aspects\"] = []\n","        for xx in range(1,aspect_number):         \n","            if df.loc[ii,\"aspect_term_\"+str(xx)] != None:\n","                asp_dict = {}   \n","                term = df.loc[ii,\"aspect_term_\"+str(xx)]\n","\n","                # construct aspect position on token level\n","                asp_toks = [token.text for sentence in nlp(term).sentences for token in sentence.tokens]\n","                asp_ind = [list(locate(tokens, lambda a: a == tok)) for tok in asp_toks]\n","\n","                # for aspects appearing only once in text, take the correct position\n","                # otherwise set to None\n","                if len(asp_ind[0]) == 1:\n","                    from_index = asp_ind[0][0]\n","                else:\n","                    from_index = None\n","                if len(asp_ind[-1]) == 1:\n","                    to_index = asp_ind[-1][0] \n","                else: \n","                    to_index = None\n","\n","                # if both start and end pos are unknown, \n","                # e.g. for single-word aspects, \n","                # take character positions for help\n","                if from_index == None and to_index == None and len(asp_ind[0]) != 0:\n","                    print(ii, \": \", text)\n","                    print(\"original term: \",term)\n","                    all_char_from = [i for i in range(len(text)) if text.startswith(asp_toks[0], i)]\n","                    print(\"all start chars: \",all_char_from)\n","                    corr_char_from = int(df.loc[ii, \"aspect_from_\"+str(xx)])\n","                    print(\"correct start char: \",corr_char_from)\n","                    print(\"text beginning at correct start char: \", text[corr_char_from:])\n","                    print(\"tokens: \",tokens)\n","                    print(\"original asp tokens: \", asp_toks)\n","                    print(\"original asp indices: \",asp_ind)\n","                    if corr_char_from == max(all_char_from):\n","                        from_index = asp_ind[0][-1]\n","                    elif corr_char_from == min(all_char_from):\n","                        from_index = asp_ind[0][0]\n","\n","                # in case of missing start/end positions,\n","                # try to find \"to\"/\"from\" using aspect token number as distance\n","                if from_index == None and to_index != None:\n","                    from_index = to_index - len(asp_toks) +1\n","                if to_index == None and from_index != None:\n","                    to_index = from_index + len(asp_toks) -1\n","\n","                # correct tokenization errors in aspect term tokenization\n","                if from_index == None or to_index == None or asp_toks != tokens[from_index:to_index+1]:\n","\n","                    print(\"Tokenization Error in line \",ii,\"!\")\n","                    for pos, tok in enumerate(tokens):\n","                        print(pos, tok)\n","                    print(\"aspect term: \", term)\n","                    print(\"original asp tokens: \", asp_toks)\n","\n","                    from_index = int(input(\"start position?\"))\n","                    to_index = int(input(\"end position?\"))\n","\n","                    # add manually stated positions to dict for reproducibility\n","                    manual_pos[text] = {}\n","                    manual_pos[text][term] = {}\n","                    manual_pos[text][term][\"from\"] = from_index\n","                    manual_pos[text][term][\"to\"] = to_index\n","                    print(manual_pos)\n","\n","                    print(\"Final aspect tokens: \", tokens[from_index:to_index+1])\n","\n","                asp_dict[\"from\"] = from_index\n","                asp_dict[\"to\"] = to_index + 1\n","\n","    with open(aspect_path+\"semeval_rest_train.json\",\"w\") as f:\n","        json.dump(manual_pos, f)\n","\n","json_make_pos(data_1)\n","'''"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12 :  The pizza is the best if you like thin crusted pizza.\n","original term:  pizza\n","all start chars:  [4, 47]\n","correct start char:  4\n","text beginning at correct start char:  pizza is the best if you like thin crusted pizza.\n","tokens:  ['The', 'pizza', 'is', 'the', 'best', 'if', 'you', 'like', 'thin', 'crusted', 'pizza', '.']\n","original asp tokens:  ['pizza']\n","original asp indices:  [[1, 10]]\n","26 :  I stumbled upon this second floor walk-up two Fridays ago when I was with two friends in town from L.A. Being serious sushi lovers, we sat at the sushi bar to be closer to the action.\n","original term:  sushi\n","all start chars:  [118, 146]\n","correct start char:  118\n","text beginning at correct start char:  sushi lovers, we sat at the sushi bar to be closer to the action.\n","tokens:  ['I', 'stumbled', 'upon', 'this', 'second', 'floor', 'walk', '-', 'up', 'two', 'Fridays', 'ago', 'when', 'I', 'was', 'with', 'two', 'friends', 'in', 'town', 'from', 'L.A.', 'Being', 'serious', 'sushi', 'lovers', ',', 'we', 'sat', 'at', 'the', 'sushi', 'bar', 'to', 'be', 'closer', 'to', 'the', 'action', '.']\n","original asp tokens:  ['sushi']\n","original asp indices:  [[24, 31]]\n","86 :  Lahore is a great place to duck into late-night when you need some really tasty food on the cheap -- you'll likely have trouble finishing the amount of food you get for FOUR DOLLARS.\n","original term:  food\n","all start chars:  [80, 152]\n","correct start char:  80\n","text beginning at correct start char:  food on the cheap -- you'll likely have trouble finishing the amount of food you get for FOUR DOLLARS.\n","tokens:  ['Lahore', 'is', 'a', 'great', 'place', 'to', 'duck', 'into', 'late', '-', 'night', 'when', 'you', 'need', 'some', 'really', 'tasty', 'food', 'on', 'the', 'cheap', '--', 'you', \"'ll\", 'likely', 'have', 'trouble', 'finishing', 'the', 'amount', 'of', 'food', 'you', 'get', 'for', 'FOUR', 'DOLLARS', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[17, 31]]\n","86 :  Lahore is a great place to duck into late-night when you need some really tasty food on the cheap -- you'll likely have trouble finishing the amount of food you get for FOUR DOLLARS.\n","original term:  food\n","all start chars:  [80, 152]\n","correct start char:  152\n","text beginning at correct start char:  food you get for FOUR DOLLARS.\n","tokens:  ['Lahore', 'is', 'a', 'great', 'place', 'to', 'duck', 'into', 'late', '-', 'night', 'when', 'you', 'need', 'some', 'really', 'tasty', 'food', 'on', 'the', 'cheap', '--', 'you', \"'ll\", 'likely', 'have', 'trouble', 'finishing', 'the', 'amount', 'of', 'food', 'you', 'get', 'for', 'FOUR', 'DOLLARS', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[17, 31]]\n","100 :  Yes, they use fancy ingredients, but even fancy ingredients don't make for good pizza unless someone knows how to get the crust right.\n","original term:  ingredients\n","all start chars:  [20, 48]\n","correct start char:  20\n","text beginning at correct start char:  ingredients, but even fancy ingredients don't make for good pizza unless someone knows how to get the crust right.\n","tokens:  ['Yes', ',', 'they', 'use', 'fancy', 'ingredients', ',', 'but', 'even', 'fancy', 'ingredients', 'do', \"n't\", 'make', 'for', 'good', 'pizza', 'unless', 'someone', 'knows', 'how', 'to', 'get', 'the', 'crust', 'right', '.']\n","original asp tokens:  ['ingredients']\n","original asp indices:  [[5, 10]]\n","100 :  Yes, they use fancy ingredients, but even fancy ingredients don't make for good pizza unless someone knows how to get the crust right.\n","original term:  ingredients\n","all start chars:  [20, 48]\n","correct start char:  48\n","text beginning at correct start char:  ingredients don't make for good pizza unless someone knows how to get the crust right.\n","tokens:  ['Yes', ',', 'they', 'use', 'fancy', 'ingredients', ',', 'but', 'even', 'fancy', 'ingredients', 'do', \"n't\", 'make', 'for', 'good', 'pizza', 'unless', 'someone', 'knows', 'how', 'to', 'get', 'the', 'crust', 'right', '.']\n","original asp tokens:  ['ingredients']\n","original asp indices:  [[5, 10]]\n","Tokenization Error in line  118 !\n","0 The\n","1 atmosphere\n","2 was\n","3 crowded\n","4 but\n","5 it\n","6 was\n","7 a\n","8 great\n","9 bistro-\n","10 type\n","11 vibe\n","12 .\n","aspect term:  bistro-type vibe\n","original asp tokens:  ['bistro', '-', 'type', 'vibe']\n","start position?9\n","end position?11\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}}\n","Final aspect tokens:  ['bistro-', 'type', 'vibe']\n","122 :  The fish is fresh but the variety of fish is nothing out of ordinary.\n","original term:  fish\n","all start chars:  [4, 37]\n","correct start char:  4\n","text beginning at correct start char:  fish is fresh but the variety of fish is nothing out of ordinary.\n","tokens:  ['The', 'fish', 'is', 'fresh', 'but', 'the', 'variety', 'of', 'fish', 'is', 'nothing', 'out', 'of', 'ordinary', '.']\n","original asp tokens:  ['fish']\n","original asp indices:  [[1, 8]]\n","164 :  We are very particular about sushi and were both please with every choice which included: ceviche mix (special), crab dumplings, assorted sashimi, sushi and rolls, two types of sake, and the banana tempura.\n","original term:  sushi\n","all start chars:  [29, 147]\n","correct start char:  29\n","text beginning at correct start char:  sushi and were both please with every choice which included: ceviche mix (special), crab dumplings, assorted sashimi, sushi and rolls, two types of sake, and the banana tempura.\n","tokens:  ['We', 'are', 'very', 'particular', 'about', 'sushi', 'and', 'were', 'both', 'please', 'with', 'every', 'choice', 'which', 'included', ':', 'ceviche', 'mix', '(', 'special', ')', ',', 'crab', 'dumplings', ',', 'assorted', 'sashimi', ',', 'sushi', 'and', 'rolls', ',', 'two', 'types', 'of', 'sake', ',', 'and', 'the', 'banana', 'tempura', '.']\n","original asp tokens:  ['sushi']\n","original asp indices:  [[5, 28]]\n","164 :  We are very particular about sushi and were both please with every choice which included: ceviche mix (special), crab dumplings, assorted sashimi, sushi and rolls, two types of sake, and the banana tempura.\n","original term:  sushi\n","all start chars:  [29, 147]\n","correct start char:  147\n","text beginning at correct start char:  sushi and rolls, two types of sake, and the banana tempura.\n","tokens:  ['We', 'are', 'very', 'particular', 'about', 'sushi', 'and', 'were', 'both', 'please', 'with', 'every', 'choice', 'which', 'included', ':', 'ceviche', 'mix', '(', 'special', ')', ',', 'crab', 'dumplings', ',', 'assorted', 'sashimi', ',', 'sushi', 'and', 'rolls', ',', 'two', 'types', 'of', 'sake', ',', 'and', 'the', 'banana', 'tempura', '.']\n","original asp tokens:  ['sushi']\n","original asp indices:  [[5, 28]]\n","166 :  Ok, so the servers wander around a little clueless, but there's more than enough servers for the crowd they get -- it's fine, you just have to make a small effort to get their attention.\n","original term:  servers\n","all start chars:  [11, 81]\n","correct start char:  11\n","text beginning at correct start char:  servers wander around a little clueless, but there's more than enough servers for the crowd they get -- it's fine, you just have to make a small effort to get their attention.\n","tokens:  ['Ok', ',', 'so', 'the', 'servers', 'wander', 'around', 'a', 'little', 'clueless', ',', 'but', 'there', \"'s\", 'more', 'than', 'enough', 'servers', 'for', 'the', 'crowd', 'they', 'get', '--', 'it', \"'s\", 'fine', ',', 'you', 'just', 'have', 'to', 'make', 'a', 'small', 'effort', 'to', 'get', 'their', 'attention', '.']\n","original asp tokens:  ['servers']\n","original asp indices:  [[4, 17]]\n","169 :  The takeout menu says to keep an eye out for an expanded menu offering more italian dishes, I can't wait!\n","original term:  menu\n","all start chars:  [12, 57]\n","correct start char:  57\n","text beginning at correct start char:  menu offering more italian dishes, I can't wait!\n","tokens:  ['The', 'takeout', 'menu', 'says', 'to', 'keep', 'an', 'eye', 'out', 'for', 'an', 'expanded', 'menu', 'offering', 'more', 'italian', 'dishes', ',', 'I', 'ca', \"n't\", 'wait', '!']\n","original asp tokens:  ['menu']\n","original asp indices:  [[2, 12]]\n","186 :  We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.\n","original term:  bar\n","all start chars:  [29, 86, 165]\n","correct start char:  29\n","text beginning at correct start char:  bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.\n","tokens:  ['We', 'were', 'still', 'sitting', 'at', 'the', 'bar', 'while', 'we', 'drank', 'the', 'sangria', ',', 'but', 'facing', 'away', 'from', 'the', 'bar', 'when', 'we', 'turned', 'back', 'around', ',', 'the', '$', '2', 'was', 'gone', 'the', 'people', 'next', 'to', 'us', 'said', 'the', 'bartender', 'took', 'it', '.']\n","original asp tokens:  ['bar']\n","original asp indices:  [[6, 18]]\n","186 :  We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.\n","original term:  bar\n","all start chars:  [29, 86, 165]\n","correct start char:  86\n","text beginning at correct start char:  bar when we turned back around, the $2 was gone the people next to us said the bartender took it.\n","tokens:  ['We', 'were', 'still', 'sitting', 'at', 'the', 'bar', 'while', 'we', 'drank', 'the', 'sangria', ',', 'but', 'facing', 'away', 'from', 'the', 'bar', 'when', 'we', 'turned', 'back', 'around', ',', 'the', '$', '2', 'was', 'gone', 'the', 'people', 'next', 'to', 'us', 'said', 'the', 'bartender', 'took', 'it', '.']\n","original asp tokens:  ['bar']\n","original asp indices:  [[6, 18]]\n","Tokenization Error in line  186 !\n","0 We\n","1 were\n","2 still\n","3 sitting\n","4 at\n","5 the\n","6 bar\n","7 while\n","8 we\n","9 drank\n","10 the\n","11 sangria\n","12 ,\n","13 but\n","14 facing\n","15 away\n","16 from\n","17 the\n","18 bar\n","19 when\n","20 we\n","21 turned\n","22 back\n","23 around\n","24 ,\n","25 the\n","26 $\n","27 2\n","28 was\n","29 gone\n","30 the\n","31 people\n","32 next\n","33 to\n","34 us\n","35 said\n","36 the\n","37 bartender\n","38 took\n","39 it\n","40 .\n","aspect term:  bar\n","original asp tokens:  ['bar']\n","start position?18\n","end position?18\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}}\n","Final aspect tokens:  ['bar']\n","212 :  It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\n","original term:  roll\n","all start chars:  [36, 60, 74]\n","correct start char:  36\n","text beginning at correct start char:  roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\n","tokens:  ['It', 'costs', '$', '2', 'extra', 'to', 'turn', 'a', 'regular', 'roll', 'into', 'an', 'inside', '-', 'out', 'roll', ',', 'but', 'the', 'roll', 'more', 'than', 'triples', 'in', 'size', ',', 'and', 'that', \"'s\", 'not', 'just', 'from', 'the', 'rice', '.']\n","original asp tokens:  ['roll']\n","original asp indices:  [[9, 15, 19]]\n","212 :  It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\n","original term:  roll\n","all start chars:  [36, 60, 74]\n","correct start char:  60\n","text beginning at correct start char:  roll, but the roll more than triples in size, and that's not just from the rice.\n","tokens:  ['It', 'costs', '$', '2', 'extra', 'to', 'turn', 'a', 'regular', 'roll', 'into', 'an', 'inside', '-', 'out', 'roll', ',', 'but', 'the', 'roll', 'more', 'than', 'triples', 'in', 'size', ',', 'and', 'that', \"'s\", 'not', 'just', 'from', 'the', 'rice', '.']\n","original asp tokens:  ['roll']\n","original asp indices:  [[9, 15, 19]]\n","Tokenization Error in line  212 !\n","0 It\n","1 costs\n","2 $\n","3 2\n","4 extra\n","5 to\n","6 turn\n","7 a\n","8 regular\n","9 roll\n","10 into\n","11 an\n","12 inside\n","13 -\n","14 out\n","15 roll\n","16 ,\n","17 but\n","18 the\n","19 roll\n","20 more\n","21 than\n","22 triples\n","23 in\n","24 size\n","25 ,\n","26 and\n","27 that\n","28 's\n","29 not\n","30 just\n","31 from\n","32 the\n","33 rice\n","34 .\n","aspect term:  roll\n","original asp tokens:  ['roll']\n","start position?15\n","end position?15\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}}\n","Final aspect tokens:  ['roll']\n","212 :  It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\n","original term:  roll\n","all start chars:  [36, 60, 74]\n","correct start char:  74\n","text beginning at correct start char:  roll more than triples in size, and that's not just from the rice.\n","tokens:  ['It', 'costs', '$', '2', 'extra', 'to', 'turn', 'a', 'regular', 'roll', 'into', 'an', 'inside', '-', 'out', 'roll', ',', 'but', 'the', 'roll', 'more', 'than', 'triples', 'in', 'size', ',', 'and', 'that', \"'s\", 'not', 'just', 'from', 'the', 'rice', '.']\n","original asp tokens:  ['roll']\n","original asp indices:  [[9, 15, 19]]\n","242 :  The man that was hosting promised to save a table for our party of 7, then sat a party of 2 at the very table he was saving (mean while there were boths open all around).\n","original term:  table\n","all start chars:  [44, 104]\n","correct start char:  44\n","text beginning at correct start char:  table for our party of 7, then sat a party of 2 at the very table he was saving (mean while there were boths open all around).\n","tokens:  ['The', 'man', 'that', 'was', 'hosting', 'promised', 'to', 'save', 'a', 'table', 'for', 'our', 'party', 'of', '7', ',', 'then', 'sat', 'a', 'party', 'of', '2', 'at', 'the', 'very', 'table', 'he', 'was', 'saving', '(', 'mean', 'while', 'there', 'were', 'boths', 'open', 'all', 'around', ')', '.']\n","original asp tokens:  ['table']\n","original asp indices:  [[9, 25]]\n","242 :  The man that was hosting promised to save a table for our party of 7, then sat a party of 2 at the very table he was saving (mean while there were boths open all around).\n","original term:  table\n","all start chars:  [44, 104]\n","correct start char:  104\n","text beginning at correct start char:  table he was saving (mean while there were boths open all around).\n","tokens:  ['The', 'man', 'that', 'was', 'hosting', 'promised', 'to', 'save', 'a', 'table', 'for', 'our', 'party', 'of', '7', ',', 'then', 'sat', 'a', 'party', 'of', '2', 'at', 'the', 'very', 'table', 'he', 'was', 'saving', '(', 'mean', 'while', 'there', 'were', 'boths', 'open', 'all', 'around', ')', '.']\n","original asp tokens:  ['table']\n","original asp indices:  [[9, 25]]\n","244 :  As we were sitting eating the subpar food the manager proceeded to berate a couple of his employees for putting out the wrong containers for condiments and explained to them how expensive these containers were.\n","original term:  containers\n","all start chars:  [126, 194]\n","correct start char:  194\n","text beginning at correct start char:  containers were.\n","tokens:  ['As', 'we', 'were', 'sitting', 'eating', 'the', 'subpar', 'food', 'the', 'manager', 'proceeded', 'to', 'berate', 'a', 'couple', 'of', 'his', 'employees', 'for', 'putting', 'out', 'the', 'wrong', 'containers', 'for', 'condiments', 'and', 'explained', 'to', 'them', 'how', 'expensive', 'these', 'containers', 'were', '.']\n","original asp tokens:  ['containers']\n","original asp indices:  [[23, 33]]\n","246 :  Decor is nice and minimalist, food simple yet very well presented and cooked, and the wine list matches the food very well.\n","original term:  food\n","all start chars:  [30, 108]\n","correct start char:  30\n","text beginning at correct start char:  food simple yet very well presented and cooked, and the wine list matches the food very well.\n","tokens:  ['Decor', 'is', 'nice', 'and', 'minimalist', ',', 'food', 'simple', 'yet', 'very', 'well', 'presented', 'and', 'cooked', ',', 'and', 'the', 'wine', 'list', 'matches', 'the', 'food', 'very', 'well', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[6, 21]]\n","246 :  Decor is nice and minimalist, food simple yet very well presented and cooked, and the wine list matches the food very well.\n","original term:  food\n","all start chars:  [30, 108]\n","correct start char:  108\n","text beginning at correct start char:  food very well.\n","tokens:  ['Decor', 'is', 'nice', 'and', 'minimalist', ',', 'food', 'simple', 'yet', 'very', 'well', 'presented', 'and', 'cooked', ',', 'and', 'the', 'wine', 'list', 'matches', 'the', 'food', 'very', 'well', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[6, 21]]\n","Tokenization Error in line  287 !\n","0 Food-awesome\n","1 .\n","aspect term:  Food\n","original asp tokens:  ['Food']\n","start position?0\n","end position?0\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}}\n","Final aspect tokens:  ['Food-awesome']\n","316 :  I wouldn't even have complained at all if the food at least tasted good but the quality of food was crappy, too.\n","original term:  food\n","all start chars:  [46, 91]\n","correct start char:  46\n","text beginning at correct start char:  food at least tasted good but the quality of food was crappy, too.\n","tokens:  ['I', 'would', \"n't\", 'even', 'have', 'complained', 'at', 'all', 'if', 'the', 'food', 'at', 'least', 'tasted', 'good', 'but', 'the', 'quality', 'of', 'food', 'was', 'crappy', ',', 'too', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[10, 19]]\n","336 :  i don't usually order wine with indian so i can't comment on their wine list or their wines.\n","original term:  wine\n","all start chars:  [22, 67, 86]\n","correct start char:  22\n","text beginning at correct start char:  wine with indian so i can't comment on their wine list or their wines.\n","tokens:  ['i', 'do', \"n't\", 'usually', 'order', 'wine', 'with', 'indian', 'so', 'i', 'ca', \"n't\", 'comment', 'on', 'their', 'wine', 'list', 'or', 'their', 'wines', '.']\n","original asp tokens:  ['wine']\n","original asp indices:  [[5, 15]]\n","340 :  The food was just OK, at least for what food was available.\n","original term:  food\n","all start chars:  [4, 40]\n","correct start char:  4\n","text beginning at correct start char:  food was just OK, at least for what food was available.\n","tokens:  ['The', 'food', 'was', 'just', 'OK', ',', 'at', 'least', 'for', 'what', 'food', 'was', 'available', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 10]]\n","340 :  The food was just OK, at least for what food was available.\n","original term:  food\n","all start chars:  [4, 40]\n","correct start char:  40\n","text beginning at correct start char:  food was available.\n","tokens:  ['The', 'food', 'was', 'just', 'OK', ',', 'at', 'least', 'for', 'what', 'food', 'was', 'available', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 10]]\n","520 :  Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","original term:  table\n","all start chars:  [19, 231]\n","correct start char:  19\n","text beginning at correct start char:  table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","tokens:  ['Besides', 'having', 'the', 'table', 'we', 'had', 'been', 'promised', 'given', 'to', 'other', 'restaurant', 'patrons', 'twice', 'before', 'we', 'were', 'actually', 'seated', ',', 'we', 'were', 'served', 'dishes', 'we', 'had', \"n't\", 'ordered', 'three', 'times', ',', 'received', 'one', 'of', 'our', 'orders', '20', 'minutes', 'after', 'the', 'rest', 'of', 'the', 'table', 'had', 'been', 'served', '(', 'and', 'that', 'order', 'was', 'undercooked', ')', ',', 'and', 'charged', '$', '45', 'more', 'than', 'we', 'should', 'have', 'been', 'on', 'our', 'bill', '.']\n","original asp tokens:  ['table']\n","original asp indices:  [[3, 43]]\n","520 :  Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","original term:  served\n","all start chars:  [126, 246]\n","correct start char:  126\n","text beginning at correct start char:  served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","tokens:  ['Besides', 'having', 'the', 'table', 'we', 'had', 'been', 'promised', 'given', 'to', 'other', 'restaurant', 'patrons', 'twice', 'before', 'we', 'were', 'actually', 'seated', ',', 'we', 'were', 'served', 'dishes', 'we', 'had', \"n't\", 'ordered', 'three', 'times', ',', 'received', 'one', 'of', 'our', 'orders', '20', 'minutes', 'after', 'the', 'rest', 'of', 'the', 'table', 'had', 'been', 'served', '(', 'and', 'that', 'order', 'was', 'undercooked', ')', ',', 'and', 'charged', '$', '45', 'more', 'than', 'we', 'should', 'have', 'been', 'on', 'our', 'bill', '.']\n","original asp tokens:  ['served']\n","original asp indices:  [[22, 46]]\n","520 :  Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","original term:  table\n","all start chars:  [19, 231]\n","correct start char:  231\n","text beginning at correct start char:  table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","tokens:  ['Besides', 'having', 'the', 'table', 'we', 'had', 'been', 'promised', 'given', 'to', 'other', 'restaurant', 'patrons', 'twice', 'before', 'we', 'were', 'actually', 'seated', ',', 'we', 'were', 'served', 'dishes', 'we', 'had', \"n't\", 'ordered', 'three', 'times', ',', 'received', 'one', 'of', 'our', 'orders', '20', 'minutes', 'after', 'the', 'rest', 'of', 'the', 'table', 'had', 'been', 'served', '(', 'and', 'that', 'order', 'was', 'undercooked', ')', ',', 'and', 'charged', '$', '45', 'more', 'than', 'we', 'should', 'have', 'been', 'on', 'our', 'bill', '.']\n","original asp tokens:  ['table']\n","original asp indices:  [[3, 43]]\n","520 :  Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","original term:  served\n","all start chars:  [126, 246]\n","correct start char:  246\n","text beginning at correct start char:  served (and that order was undercooked), and charged $45 more than we should have been on our bill.\n","tokens:  ['Besides', 'having', 'the', 'table', 'we', 'had', 'been', 'promised', 'given', 'to', 'other', 'restaurant', 'patrons', 'twice', 'before', 'we', 'were', 'actually', 'seated', ',', 'we', 'were', 'served', 'dishes', 'we', 'had', \"n't\", 'ordered', 'three', 'times', ',', 'received', 'one', 'of', 'our', 'orders', '20', 'minutes', 'after', 'the', 'rest', 'of', 'the', 'table', 'had', 'been', 'served', '(', 'and', 'that', 'order', 'was', 'undercooked', ')', ',', 'and', 'charged', '$', '45', 'more', 'than', 'we', 'should', 'have', 'been', 'on', 'our', 'bill', '.']\n","original asp tokens:  ['served']\n","original asp indices:  [[22, 46]]\n","549 :  if you're looking for perfect traditional sushi, go here - if you're looking for interesting combinations, try sushi of gari's (east side).\n","original term:  sushi\n","all start chars:  [42, 111]\n","correct start char:  42\n","text beginning at correct start char:  sushi, go here - if you're looking for interesting combinations, try sushi of gari's (east side).\n","tokens:  ['if', 'you', \"'re\", 'looking', 'for', 'perfect', 'traditional', 'sushi', ',', 'go', 'here', '-', 'if', 'you', \"'re\", 'looking', 'for', 'interesting', 'combinations', ',', 'try', 'sushi', 'of', 'gari', \"'s\", '(', 'east', 'side', ')', '.']\n","original asp tokens:  ['sushi']\n","original asp indices:  [[7, 21]]\n","549 :  if you're looking for perfect traditional sushi, go here - if you're looking for interesting combinations, try sushi of gari's (east side).\n","original term:  sushi\n","all start chars:  [42, 111]\n","correct start char:  111\n","text beginning at correct start char:  sushi of gari's (east side).\n","tokens:  ['if', 'you', \"'re\", 'looking', 'for', 'perfect', 'traditional', 'sushi', ',', 'go', 'here', '-', 'if', 'you', \"'re\", 'looking', 'for', 'interesting', 'combinations', ',', 'try', 'sushi', 'of', 'gari', \"'s\", '(', 'east', 'side', ')', '.']\n","original asp tokens:  ['sushi']\n","original asp indices:  [[7, 21]]\n","583 :  I had a terrific meal, and our server guided us toward a very nice wine in our price range, instead of allowing us to purchase a similarly priced wine that wasn't as good.\n","original term:  wine\n","all start chars:  [67, 146]\n","correct start char:  67\n","text beginning at correct start char:  wine in our price range, instead of allowing us to purchase a similarly priced wine that wasn't as good.\n","tokens:  ['I', 'had', 'a', 'terrific', 'meal', ',', 'and', 'our', 'server', 'guided', 'us', 'toward', 'a', 'very', 'nice', 'wine', 'in', 'our', 'price', 'range', ',', 'instead', 'of', 'allowing', 'us', 'to', 'purchase', 'a', 'similarly', 'priced', 'wine', 'that', 'was', \"n't\", 'as', 'good', '.']\n","original asp tokens:  ['wine']\n","original asp indices:  [[15, 30]]\n","583 :  I had a terrific meal, and our server guided us toward a very nice wine in our price range, instead of allowing us to purchase a similarly priced wine that wasn't as good.\n","original term:  wine\n","all start chars:  [67, 146]\n","correct start char:  146\n","text beginning at correct start char:  wine that wasn't as good.\n","tokens:  ['I', 'had', 'a', 'terrific', 'meal', ',', 'and', 'our', 'server', 'guided', 'us', 'toward', 'a', 'very', 'nice', 'wine', 'in', 'our', 'price', 'range', ',', 'instead', 'of', 'allowing', 'us', 'to', 'purchase', 'a', 'similarly', 'priced', 'wine', 'that', 'was', \"n't\", 'as', 'good', '.']\n","original asp tokens:  ['wine']\n","original asp indices:  [[15, 30]]\n","Tokenization Error in line  626 !\n","0 So\n","1 much\n","2 more\n","3 than\n","4 the\n","5 usual\n","6 bar\n","7 food\n","8 ,\n","9 go\n","10 there\n","11 to\n","12 enjoy\n","13 the\n","14 menu\n","15 while\n","16 sampling\n","17 one\n","18 of\n","19 their\n","20 hand\n","21 -\n","22 crafted\n","23 beers\n","24 .\n","aspect term:  hand-crafted beers\n","original asp tokens:  ['hand', '-crafted', 'beers']\n","start position?20\n","end position?23\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}}\n","Final aspect tokens:  ['hand', '-', 'crafted', 'beers']\n","640 :  all the food was excellent - considering the quality of food in most moderately priced restaurants is mediocre this was slightly more pricey and well worth it.\n","original term:  food\n","all start chars:  [8, 56]\n","correct start char:  8\n","text beginning at correct start char:  food was excellent - considering the quality of food in most moderately priced restaurants is mediocre this was slightly more pricey and well worth it.\n","tokens:  ['all', 'the', 'food', 'was', 'excellent', '-', 'considering', 'the', 'quality', 'of', 'food', 'in', 'most', 'moderately', 'priced', 'restaurants', 'is', 'mediocre', 'this', 'was', 'slightly', 'more', 'pricey', 'and', 'well', 'worth', 'it', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[2, 10]]\n","642 :  I had the cod with paella (spicy and very filling, I'm a big eater and could only eat half) while my boyfriend had the classic fish and chips (again, a big serving - at least 5 pieces of fish and a basketful of fries).\n","original term:  fish\n","all start chars:  [127, 187]\n","correct start char:  187\n","text beginning at correct start char:  fish and a basketful of fries).\n","tokens:  ['I', 'had', 'the', 'cod', 'with', 'paella', '(', 'spicy', 'and', 'very', 'filling', ',', 'I', \"'m\", 'a', 'big', 'eater', 'and', 'could', 'only', 'eat', 'half', ')', 'while', 'my', 'boyfriend', 'had', 'the', 'classic', 'fish', 'and', 'chips', '(', 'again', ',', 'a', 'big', 'serving', '-', 'at', 'least', '5', 'pieces', 'of', 'fish', 'and', 'a', 'basketful', 'of', 'fries', ')', '.']\n","original asp tokens:  ['fish']\n","original asp indices:  [[29, 44]]\n","668 :  The food is a diamond in rough -- the food is delicious and homemade with the perfect balance of herbs and tomatoes.\n","original term:  food\n","all start chars:  [4, 38]\n","correct start char:  4\n","text beginning at correct start char:  food is a diamond in rough -- the food is delicious and homemade with the perfect balance of herbs and tomatoes.\n","tokens:  ['The', 'food', 'is', 'a', 'diamond', 'in', 'rough', '--', 'the', 'food', 'is', 'delicious', 'and', 'homemade', 'with', 'the', 'perfect', 'balance', 'of', 'herbs', 'and', 'tomatoes', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 9]]\n","668 :  The food is a diamond in rough -- the food is delicious and homemade with the perfect balance of herbs and tomatoes.\n","original term:  food\n","all start chars:  [4, 38]\n","correct start char:  38\n","text beginning at correct start char:  food is delicious and homemade with the perfect balance of herbs and tomatoes.\n","tokens:  ['The', 'food', 'is', 'a', 'diamond', 'in', 'rough', '--', 'the', 'food', 'is', 'delicious', 'and', 'homemade', 'with', 'the', 'perfect', 'balance', 'of', 'herbs', 'and', 'tomatoes', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 9]]\n","715 :  The rice to fish ration was also good--they didn't try to overpack the rice.\n","original term:  rice\n","all start chars:  [4, 71]\n","correct start char:  71\n","text beginning at correct start char:  rice.\n","tokens:  ['The', 'rice', 'to', 'fish', 'ration', 'was', 'also', 'good', '--', 'they', 'did', \"n't\", 'try', 'to', 'overpack', 'the', 'rice', '.']\n","original asp tokens:  ['rice']\n","original asp indices:  [[1, 16]]\n","725 :  I ordered the crab cocktail and it was soaked in a lime juice concoction where all you could taste was the lime.\n","original term:  lime\n","all start chars:  [51, 107]\n","correct start char:  107\n","text beginning at correct start char:  lime.\n","tokens:  ['I', 'ordered', 'the', 'crab', 'cocktail', 'and', 'it', 'was', 'soaked', 'in', 'a', 'lime', 'juice', 'concoction', 'where', 'all', 'you', 'could', 'taste', 'was', 'the', 'lime', '.']\n","original asp tokens:  ['lime']\n","original asp indices:  [[11, 21]]\n","735 :  Very romantic fires - I've literally spent hours at Lanterna, drinking wine from their extensive wine and enjoying the ambience.\n","original term:  wine\n","all start chars:  [71, 97]\n","correct start char:  71\n","text beginning at correct start char:  wine from their extensive wine and enjoying the ambience.\n","tokens:  ['Very', 'romantic', 'fires', '-', 'I', \"'ve\", 'literally', 'spent', 'hours', 'at', 'Lanterna', ',', 'drinking', 'wine', 'from', 'their', 'extensive', 'wine', 'and', 'enjoying', 'the', 'ambience', '.']\n","original asp tokens:  ['wine']\n","original asp indices:  [[13, 17]]\n","735 :  Very romantic fires - I've literally spent hours at Lanterna, drinking wine from their extensive wine and enjoying the ambience.\n","original term:  wine\n","all start chars:  [71, 97]\n","correct start char:  97\n","text beginning at correct start char:  wine and enjoying the ambience.\n","tokens:  ['Very', 'romantic', 'fires', '-', 'I', \"'ve\", 'literally', 'spent', 'hours', 'at', 'Lanterna', ',', 'drinking', 'wine', 'from', 'their', 'extensive', 'wine', 'and', 'enjoying', 'the', 'ambience', '.']\n","original asp tokens:  ['wine']\n","original asp indices:  [[13, 17]]\n","787 :  my picks: Guizhou chicken, fish with hot bean source, fish fillet in spicy source (special menu).\n","original term:  fish with hot bean source\n","all start chars:  [27, 54]\n","correct start char:  27\n","text beginning at correct start char:  fish with hot bean source, fish fillet in spicy source (special menu).\n","tokens:  ['my', 'picks', ':', 'Guizhou', 'chicken', ',', 'fish', 'with', 'hot', 'bean', 'source', ',', 'fish', 'fillet', 'in', 'spicy', 'source', '(', 'special', 'menu', ')', '.']\n","original asp tokens:  ['fish', 'with', 'hot', 'bean', 'source']\n","original asp indices:  [[6, 12], [7], [8], [9], [10, 16]]\n","787 :  my picks: Guizhou chicken, fish with hot bean source, fish fillet in spicy source (special menu).\n","original term:  fish fillet in spicy source\n","all start chars:  [27, 54]\n","correct start char:  54\n","text beginning at correct start char:  fish fillet in spicy source (special menu).\n","tokens:  ['my', 'picks', ':', 'Guizhou', 'chicken', ',', 'fish', 'with', 'hot', 'bean', 'source', ',', 'fish', 'fillet', 'in', 'spicy', 'source', '(', 'special', 'menu', ')', '.']\n","original asp tokens:  ['fish', 'fillet', 'in', 'spicy', 'source']\n","original asp indices:  [[6, 12], [13], [14], [15], [10, 16]]\n","806 :  $20 gets you unlimited sushi of a very high quality- I even took a friend here from Japan who said it was one of the best sushi places in the US that he has been to.\n","original term:  sushi\n","all start chars:  [23, 122]\n","correct start char:  23\n","text beginning at correct start char:  sushi of a very high quality- I even took a friend here from Japan who said it was one of the best sushi places in the US that he has been to.\n","tokens:  ['$', '20', 'gets', 'you', 'unlimited', 'sushi', 'of', 'a', 'very', 'high', 'quality', '-', 'I', 'even', 'took', 'a', 'friend', 'here', 'from', 'Japan', 'who', 'said', 'it', 'was', 'one', 'of', 'the', 'best', 'sushi', 'places', 'in', 'the', 'US', 'that', 'he', 'has', 'been', 'to', '.']\n","original asp tokens:  ['sushi']\n","original asp indices:  [[5, 28]]\n","823 :  It was not above ordinary and the beef version had cheap (undercooked) beef.\n","original term:  beef\n","all start chars:  [34, 71]\n","correct start char:  71\n","text beginning at correct start char:  beef.\n","tokens:  ['It', 'was', 'not', 'above', 'ordinary', 'and', 'the', 'beef', 'version', 'had', 'cheap', '(', 'undercooked', ')', 'beef', '.']\n","original asp tokens:  ['beef']\n","original asp indices:  [[7, 14]]\n","843 :  BUt their best dish is thh Thai spiced curry noodles with shrimp - a dish that would cost $23.95 is most places, but it is $16 here.\n","original term:  dish\n","all start chars:  [15, 69]\n","correct start char:  15\n","text beginning at correct start char:  dish is thh Thai spiced curry noodles with shrimp - a dish that would cost $23.95 is most places, but it is $16 here.\n","tokens:  ['BUt', 'their', 'best', 'dish', 'is', 'thh', 'Thai', 'spiced', 'curry', 'noodles', 'with', 'shrimp', '-', 'a', 'dish', 'that', 'would', 'cost', '$', '23.95', 'is', 'most', 'places', ',', 'but', 'it', 'is', '$', '16', 'here', '.']\n","original asp tokens:  ['dish']\n","original asp indices:  [[3, 14]]\n","843 :  BUt their best dish is thh Thai spiced curry noodles with shrimp - a dish that would cost $23.95 is most places, but it is $16 here.\n","original term:  dish\n","all start chars:  [15, 69]\n","correct start char:  69\n","text beginning at correct start char:  dish that would cost $23.95 is most places, but it is $16 here.\n","tokens:  ['BUt', 'their', 'best', 'dish', 'is', 'thh', 'Thai', 'spiced', 'curry', 'noodles', 'with', 'shrimp', '-', 'a', 'dish', 'that', 'would', 'cost', '$', '23.95', 'is', 'most', 'places', ',', 'but', 'it', 'is', '$', '16', 'here', '.']\n","original asp tokens:  ['dish']\n","original asp indices:  [[3, 14]]\n","865 :  An excellent alternative to fast food joints and ordering in but, the food was slightly disappointing.\n","original term:  food\n","all start chars:  [33, 70]\n","correct start char:  70\n","text beginning at correct start char:  food was slightly disappointing.\n","tokens:  ['An', 'excellent', 'alternative', 'to', 'fast', 'food', 'joints', 'and', 'ordering', 'in', 'but', ',', 'the', 'food', 'was', 'slightly', 'disappointing', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[5, 13]]\n","882 :  Ive asked a cart attendant for a lotus leaf wrapped rice and she replied back rice and just walked away.\n","original term:  rice\n","all start chars:  [52, 78]\n","correct start char:  78\n","text beginning at correct start char:  rice and just walked away.\n","tokens:  ['Ive', 'asked', 'a', 'cart', 'attendant', 'for', 'a', 'lotus', 'leaf', 'wrapped', 'rice', 'and', 'she', 'replied', 'back', 'rice', 'and', 'just', 'walked', 'away', '.']\n","original asp tokens:  ['rice']\n","original asp indices:  [[10, 15]]\n","897 :  After complaining about the chicken dish, the manager came over to tell us that, no one had ever complained before, and that we just didn't know what the dish was supposed to taste like.\n","original term:  dish\n","all start chars:  [36, 154]\n","correct start char:  154\n","text beginning at correct start char:  dish was supposed to taste like.\n","tokens:  ['After', 'complaining', 'about', 'the', 'chicken', 'dish', ',', 'the', 'manager', 'came', 'over', 'to', 'tell', 'us', 'that', ',', 'no', 'one', 'had', 'ever', 'complained', 'before', ',', 'and', 'that', 'we', 'just', 'did', \"n't\", 'know', 'what', 'the', 'dish', 'was', 'supposed', 'to', 'taste', 'like', '.']\n","original asp tokens:  ['dish']\n","original asp indices:  [[5, 32]]\n","911 :  While we enjoyed the food, we were highly disappointed by the poor service (waiter was not quite competent and SLOW service) and lack of remorse.\n","original term:  service\n","all start chars:  [67, 116]\n","correct start char:  67\n","text beginning at correct start char:  service (waiter was not quite competent and SLOW service) and lack of remorse.\n","tokens:  ['While', 'we', 'enjoyed', 'the', 'food', ',', 'we', 'were', 'highly', 'disappointed', 'by', 'the', 'poor', 'service', '(', 'waiter', 'was', 'not', 'quite', 'competent', 'and', 'SLOW', 'service', ')', 'and', 'lack', 'of', 'remorse', '.']\n","original asp tokens:  ['service']\n","original asp indices:  [[13, 22]]\n","911 :  While we enjoyed the food, we were highly disappointed by the poor service (waiter was not quite competent and SLOW service) and lack of remorse.\n","original term:  service\n","all start chars:  [67, 116]\n","correct start char:  116\n","text beginning at correct start char:  service) and lack of remorse.\n","tokens:  ['While', 'we', 'enjoyed', 'the', 'food', ',', 'we', 'were', 'highly', 'disappointed', 'by', 'the', 'poor', 'service', '(', 'waiter', 'was', 'not', 'quite', 'competent', 'and', 'SLOW', 'service', ')', 'and', 'lack', 'of', 'remorse', '.']\n","original asp tokens:  ['service']\n","original asp indices:  [[13, 22]]\n","914 :  The food is very good too but for the most part, it's just regular food, nothing special.\n","original term:  food\n","all start chars:  [4, 67]\n","correct start char:  4\n","text beginning at correct start char:  food is very good too but for the most part, it's just regular food, nothing special.\n","tokens:  ['The', 'food', 'is', 'very', 'good', 'too', 'but', 'for', 'the', 'most', 'part', ',', 'it', \"'s\", 'just', 'regular', 'food', ',', 'nothing', 'special', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 16]]\n","914 :  The food is very good too but for the most part, it's just regular food, nothing special.\n","original term:  food\n","all start chars:  [4, 67]\n","correct start char:  67\n","text beginning at correct start char:  food, nothing special.\n","tokens:  ['The', 'food', 'is', 'very', 'good', 'too', 'but', 'for', 'the', 'most', 'part', ',', 'it', \"'s\", 'just', 'regular', 'food', ',', 'nothing', 'special', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 16]]\n","919 :  Guacamole+shrimp appetizer was really great, we both had the filet, very good, didn't much like the frites that came with, but the filet was so good, neither of us cared.\n","original term:  filet\n","all start chars:  [61, 131]\n","correct start char:  61\n","text beginning at correct start char:  filet, very good, didn't much like the frites that came with, but the filet was so good, neither of us cared.\n","tokens:  ['Guacamole', '+', 'shrimp', 'appetizer', 'was', 'really', 'great', ',', 'we', 'both', 'had', 'the', 'filet', ',', 'very', 'good', ',', 'did', \"n't\", 'much', 'like', 'the', 'frites', 'that', 'came', 'with', ',', 'but', 'the', 'filet', 'was', 'so', 'good', ',', 'neither', 'of', 'us', 'cared', '.']\n","original asp tokens:  ['filet']\n","original asp indices:  [[12, 29]]\n","919 :  Guacamole+shrimp appetizer was really great, we both had the filet, very good, didn't much like the frites that came with, but the filet was so good, neither of us cared.\n","original term:  filet\n","all start chars:  [61, 131]\n","correct start char:  131\n","text beginning at correct start char:  filet was so good, neither of us cared.\n","tokens:  ['Guacamole', '+', 'shrimp', 'appetizer', 'was', 'really', 'great', ',', 'we', 'both', 'had', 'the', 'filet', ',', 'very', 'good', ',', 'did', \"n't\", 'much', 'like', 'the', 'frites', 'that', 'came', 'with', ',', 'but', 'the', 'filet', 'was', 'so', 'good', ',', 'neither', 'of', 'us', 'cared', '.']\n","original asp tokens:  ['filet']\n","original asp indices:  [[12, 29]]\n","Tokenization Error in line  956 !\n","0 Fluke\n","1 sashimi\n","2 drizzled\n","3 with\n","4 jalapeno-\n","5 lime\n","6 olive\n","7 oil\n","8 ,\n","9 the\n","10 fruit\n","11 of\n","12 the\n","13 oil\n","14 nicely\n","15 highlighting\n","16 the\n","17 fish\n","18 's\n","19 sweetness\n","20 .\n","aspect term:  jalapeno-lime olive oil\n","original asp tokens:  ['jalapeno', '-', 'lime', 'olive', 'oil']\n","start position?4\n","end position?7\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}}\n","Final aspect tokens:  ['jalapeno-', 'lime', 'olive', 'oil']\n","Tokenization Error in line  963 !\n","0 Although\n","1 the\n","2 tables\n","3 may\n","4 be\n","5 closely\n","6 situated\n","7 ,\n","8 the\n","9 candle\n","10 -\n","11 light\n","12 ,\n","13 food\n","14 -\n","15 quality\n","16 and\n","17 service\n","18 overcompensate\n","19 .\n","aspect term:  candle-light\n","original asp tokens:  ['candle', '-light']\n","start position?9\n","end position?11\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'candle-light': {'from': 9, 'to': 11}}}\n","Final aspect tokens:  ['candle', '-', 'light']\n","Tokenization Error in line  963 !\n","0 Although\n","1 the\n","2 tables\n","3 may\n","4 be\n","5 closely\n","6 situated\n","7 ,\n","8 the\n","9 candle\n","10 -\n","11 light\n","12 ,\n","13 food\n","14 -\n","15 quality\n","16 and\n","17 service\n","18 overcompensate\n","19 .\n","aspect term:  food-quality\n","original asp tokens:  ['food-quality']\n","start position?13\n","end position?15\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}}\n","Final aspect tokens:  ['food', '-', 'quality']\n","993 :  I like Mamoun's food as well, but side by side, Kati Rolls just produce tastier food hands down.\n","original term:  food\n","all start chars:  [16, 80]\n","correct start char:  16\n","text beginning at correct start char:  food as well, but side by side, Kati Rolls just produce tastier food hands down.\n","tokens:  ['I', 'like', 'Mamoun', \"'s\", 'food', 'as', 'well', ',', 'but', 'side', 'by', 'side', ',', 'Kati', 'Rolls', 'just', 'produce', 'tastier', 'food', 'hands', 'down', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[4, 18]]\n","993 :  I like Mamoun's food as well, but side by side, Kati Rolls just produce tastier food hands down.\n","original term:  food\n","all start chars:  [16, 80]\n","correct start char:  80\n","text beginning at correct start char:  food hands down.\n","tokens:  ['I', 'like', 'Mamoun', \"'s\", 'food', 'as', 'well', ',', 'but', 'side', 'by', 'side', ',', 'Kati', 'Rolls', 'just', 'produce', 'tastier', 'food', 'hands', 'down', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[4, 18]]\n","1019 :  sometimes i get bad food and bad service, sometimes i get good good and bad service.\n","original term:  service\n","all start chars:  [33, 76]\n","correct start char:  33\n","text beginning at correct start char:  service, sometimes i get good good and bad service.\n","tokens:  ['sometimes', 'i', 'get', 'bad', 'food', 'and', 'bad', 'service', ',', 'sometimes', 'i', 'get', 'good', 'good', 'and', 'bad', 'service', '.']\n","original asp tokens:  ['service']\n","original asp indices:  [[7, 16]]\n","1019 :  sometimes i get bad food and bad service, sometimes i get good good and bad service.\n","original term:  service\n","all start chars:  [33, 76]\n","correct start char:  76\n","text beginning at correct start char:  service.\n","tokens:  ['sometimes', 'i', 'get', 'bad', 'food', 'and', 'bad', 'service', ',', 'sometimes', 'i', 'get', 'good', 'good', 'and', 'bad', 'service', '.']\n","original asp tokens:  ['service']\n","original asp indices:  [[7, 16]]\n","1019 :  sometimes i get bad food and bad service, sometimes i get good good and bad service.\n","original term:  good\n","all start chars:  [58, 63]\n","correct start char:  63\n","text beginning at correct start char:  good and bad service.\n","tokens:  ['sometimes', 'i', 'get', 'bad', 'food', 'and', 'bad', 'service', ',', 'sometimes', 'i', 'get', 'good', 'good', 'and', 'bad', 'service', '.']\n","original asp tokens:  ['good']\n","original asp indices:  [[12, 13]]\n","1089 :  night without a reservation, we had to wait at the bar for a little while, but the manager was so nice and made our wait a great experience.\n","original term:  wait\n","all start chars:  [39, 116]\n","correct start char:  116\n","text beginning at correct start char:  wait a great experience.\n","tokens:  ['night', 'without', 'a', 'reservation', ',', 'we', 'had', 'to', 'wait', 'at', 'the', 'bar', 'for', 'a', 'little', 'while', ',', 'but', 'the', 'manager', 'was', 'so', 'nice', 'and', 'made', 'our', 'wait', 'a', 'great', 'experience', '.']\n","original asp tokens:  ['wait']\n","original asp indices:  [[8, 26]]\n","1177 :  The people with carts of food don't understand you because they don't speak English, their job is to give you the delicious food you point at.\n","original term:  food\n","all start chars:  [25, 124]\n","correct start char:  124\n","text beginning at correct start char:  food you point at.\n","tokens:  ['The', 'people', 'with', 'carts', 'of', 'food', 'do', \"n't\", 'understand', 'you', 'because', 'they', 'do', \"n't\", 'speak', 'English', ',', 'their', 'job', 'is', 'to', 'give', 'you', 'the', 'delicious', 'food', 'you', 'point', 'at', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[5, 25]]\n","1228 :  The wait here is long for dim sum, but if you don't like sharing tables or if the typical raucous dim sum atmosphere is not your gig, this is a sleek (for Chinatown) alternative.\n","original term:  dim sum\n","all start chars:  [26, 98]\n","correct start char:  26\n","text beginning at correct start char:  dim sum, but if you don't like sharing tables or if the typical raucous dim sum atmosphere is not your gig, this is a sleek (for Chinatown) alternative.\n","tokens:  ['The', 'wait', 'here', 'is', 'long', 'for', 'dim', 'sum', ',', 'but', 'if', 'you', 'do', \"n't\", 'like', 'sharing', 'tables', 'or', 'if', 'the', 'typical', 'raucous', 'dim', 'sum', 'atmosphere', 'is', 'not', 'your', 'gig', ',', 'this', 'is', 'a', 'sleek', '(', 'for', 'Chinatown', ')', 'alternative', '.']\n","original asp tokens:  ['dim', 'sum']\n","original asp indices:  [[6, 22], [7, 23]]\n","1255 :  (food was delivered by a busboy, not waiter) We got no cheese offered for the pasta, our water and wine glasses remained EMPTY our entire meal, when we would have easily spent another $20 on wine.\n","original term:  wine\n","all start chars:  [99, 191]\n","correct start char:  191\n","text beginning at correct start char:  wine.\n","tokens:  ['(', 'food', 'was', 'delivered', 'by', 'a', 'busboy', ',', 'not', 'waiter', ')', 'We', 'got', 'no', 'cheese', 'offered', 'for', 'the', 'pasta', ',', 'our', 'water', 'and', 'wine', 'glasses', 'remained', 'EMPTY', 'our', 'entire', 'meal', ',', 'when', 'we', 'would', 'have', 'easily', 'spent', 'another', '$', '20', 'on', 'wine', '.']\n","original asp tokens:  ['wine']\n","original asp indices:  [[23, 41]]\n","1272 :  The only disappointment was the coat check girls who didn't seem to know what a customer is on a realtively non-busy night (for the coat check girls).\n","original term:  coat check girls\n","all start chars:  [32, 132]\n","correct start char:  32\n","text beginning at correct start char:  coat check girls who didn't seem to know what a customer is on a realtively non-busy night (for the coat check girls).\n","tokens:  ['The', 'only', 'disappointment', 'was', 'the', 'coat', 'check', 'girls', 'who', 'did', \"n't\", 'seem', 'to', 'know', 'what', 'a', 'customer', 'is', 'on', 'a', 'realtively', 'non-', 'busy', 'night', '(', 'for', 'the', 'coat', 'check', 'girls', ')', '.']\n","original asp tokens:  ['coat', 'check', 'girls']\n","original asp indices:  [[5, 27], [6, 28], [7, 29]]\n","1272 :  The only disappointment was the coat check girls who didn't seem to know what a customer is on a realtively non-busy night (for the coat check girls).\n","original term:  coat check girls\n","all start chars:  [32, 132]\n","correct start char:  132\n","text beginning at correct start char:  coat check girls).\n","tokens:  ['The', 'only', 'disappointment', 'was', 'the', 'coat', 'check', 'girls', 'who', 'did', \"n't\", 'seem', 'to', 'know', 'what', 'a', 'customer', 'is', 'on', 'a', 'realtively', 'non-', 'busy', 'night', '(', 'for', 'the', 'coat', 'check', 'girls', ')', '.']\n","original asp tokens:  ['coat', 'check', 'girls']\n","original asp indices:  [[5, 27], [6, 28], [7, 29]]\n","Tokenization Error in line  1304 !\n","0 The\n","1 pesto\n","2 pizza\n","3 was\n","4 excellent\n","5 ,\n","6 thin\n","7 -crust\n","8 pizza\n","9 with\n","10 a\n","11 nice\n","12 amount\n","13 of\n","14 spicy\n","15 Italian\n","16 cheese\n","17 that\n","18 I\n","19 'd\n","20 never\n","21 heard\n","22 of\n","23 before\n","24 .\n","aspect term:  thin-crust pizza\n","original asp tokens:  ['thin-crust', 'pizza']\n","start position?6\n","end position?8\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}}\n","Final aspect tokens:  ['thin', '-crust', 'pizza']\n","1349 :  The bread is the soft paratha bread (unlike the plain bread they use in Calcutta), and the stuffing is tandoori styled and very flavorful.\n","original term:  bread\n","all start chars:  [4, 30, 54]\n","correct start char:  4\n","text beginning at correct start char:  bread is the soft paratha bread (unlike the plain bread they use in Calcutta), and the stuffing is tandoori styled and very flavorful.\n","tokens:  ['The', 'bread', 'is', 'the', 'soft', 'paratha', 'bread', '(', 'unlike', 'the', 'plain', 'bread', 'they', 'use', 'in', 'Calcutta', ')', ',', 'and', 'the', 'stuffing', 'is', 'tandoori', 'styled', 'and', 'very', 'flavorful', '.']\n","original asp tokens:  ['bread']\n","original asp indices:  [[1, 6, 11]]\n","1349 :  The bread is the soft paratha bread (unlike the plain bread they use in Calcutta), and the stuffing is tandoori styled and very flavorful.\n","original term:  bread\n","all start chars:  [4, 30, 54]\n","correct start char:  54\n","text beginning at correct start char:  bread they use in Calcutta), and the stuffing is tandoori styled and very flavorful.\n","tokens:  ['The', 'bread', 'is', 'the', 'soft', 'paratha', 'bread', '(', 'unlike', 'the', 'plain', 'bread', 'they', 'use', 'in', 'Calcutta', ')', ',', 'and', 'the', 'stuffing', 'is', 'tandoori', 'styled', 'and', 'very', 'flavorful', '.']\n","original asp tokens:  ['bread']\n","original asp indices:  [[1, 6, 11]]\n","1351 :  The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\n","original term:  food\n","all start chars:  [4, 72, 113, 125, 143]\n","correct start char:  72\n","text beginning at correct start char:  food for a good price and they cater the food to any food allergies or food you don't like.\n","tokens:  ['The', 'food', 'can', 'get', 'pricey', 'but', 'the', 'prixe', 'fixe', 'tasting', 'menu', 'is', 'the', 'greatest', 'food', 'for', 'a', 'good', 'price', 'and', 'they', 'cater', 'the', 'food', 'to', 'any', 'food', 'allergies', 'or', 'food', 'you', 'do', \"n't\", 'like', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 14, 23, 26, 29]]\n","Tokenization Error in line  1351 !\n","0 The\n","1 food\n","2 can\n","3 get\n","4 pricey\n","5 but\n","6 the\n","7 prixe\n","8 fixe\n","9 tasting\n","10 menu\n","11 is\n","12 the\n","13 greatest\n","14 food\n","15 for\n","16 a\n","17 good\n","18 price\n","19 and\n","20 they\n","21 cater\n","22 the\n","23 food\n","24 to\n","25 any\n","26 food\n","27 allergies\n","28 or\n","29 food\n","30 you\n","31 do\n","32 n't\n","33 like\n","34 .\n","aspect term:  food\n","original asp tokens:  ['food']\n","start position?14\n","end position?14\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 14, 'to': 14}}}\n","Final aspect tokens:  ['food']\n","1351 :  The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\n","original term:  food\n","all start chars:  [4, 72, 113, 125, 143]\n","correct start char:  113\n","text beginning at correct start char:  food to any food allergies or food you don't like.\n","tokens:  ['The', 'food', 'can', 'get', 'pricey', 'but', 'the', 'prixe', 'fixe', 'tasting', 'menu', 'is', 'the', 'greatest', 'food', 'for', 'a', 'good', 'price', 'and', 'they', 'cater', 'the', 'food', 'to', 'any', 'food', 'allergies', 'or', 'food', 'you', 'do', \"n't\", 'like', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 14, 23, 26, 29]]\n","Tokenization Error in line  1351 !\n","0 The\n","1 food\n","2 can\n","3 get\n","4 pricey\n","5 but\n","6 the\n","7 prixe\n","8 fixe\n","9 tasting\n","10 menu\n","11 is\n","12 the\n","13 greatest\n","14 food\n","15 for\n","16 a\n","17 good\n","18 price\n","19 and\n","20 they\n","21 cater\n","22 the\n","23 food\n","24 to\n","25 any\n","26 food\n","27 allergies\n","28 or\n","29 food\n","30 you\n","31 do\n","32 n't\n","33 like\n","34 .\n","aspect term:  food\n","original asp tokens:  ['food']\n","start position?23\n","end position?23\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 23, 'to': 23}}}\n","Final aspect tokens:  ['food']\n","1351 :  The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\n","original term:  food\n","all start chars:  [4, 72, 113, 125, 143]\n","correct start char:  125\n","text beginning at correct start char:  food allergies or food you don't like.\n","tokens:  ['The', 'food', 'can', 'get', 'pricey', 'but', 'the', 'prixe', 'fixe', 'tasting', 'menu', 'is', 'the', 'greatest', 'food', 'for', 'a', 'good', 'price', 'and', 'they', 'cater', 'the', 'food', 'to', 'any', 'food', 'allergies', 'or', 'food', 'you', 'do', \"n't\", 'like', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 14, 23, 26, 29]]\n","Tokenization Error in line  1351 !\n","0 The\n","1 food\n","2 can\n","3 get\n","4 pricey\n","5 but\n","6 the\n","7 prixe\n","8 fixe\n","9 tasting\n","10 menu\n","11 is\n","12 the\n","13 greatest\n","14 food\n","15 for\n","16 a\n","17 good\n","18 price\n","19 and\n","20 they\n","21 cater\n","22 the\n","23 food\n","24 to\n","25 any\n","26 food\n","27 allergies\n","28 or\n","29 food\n","30 you\n","31 do\n","32 n't\n","33 like\n","34 .\n","aspect term:  food\n","original asp tokens:  ['food']\n","start position?26\n","end position?26\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 26, 'to': 26}}}\n","Final aspect tokens:  ['food']\n","1351 :  The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\n","original term:  food\n","all start chars:  [4, 72, 113, 125, 143]\n","correct start char:  143\n","text beginning at correct start char:  food you don't like.\n","tokens:  ['The', 'food', 'can', 'get', 'pricey', 'but', 'the', 'prixe', 'fixe', 'tasting', 'menu', 'is', 'the', 'greatest', 'food', 'for', 'a', 'good', 'price', 'and', 'they', 'cater', 'the', 'food', 'to', 'any', 'food', 'allergies', 'or', 'food', 'you', 'do', \"n't\", 'like', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 14, 23, 26, 29]]\n","1408 :  Unless you are eating in the Pizzeria side of this place, and are not in a rush, this place is a bad idea.\n","original term:  place\n","all start chars:  [51, 86]\n","correct start char:  51\n","text beginning at correct start char:  place, and are not in a rush, this place is a bad idea.\n","tokens:  ['Unless', 'you', 'are', 'eating', 'in', 'the', 'Pizzeria', 'side', 'of', 'this', 'place', ',', 'and', 'are', 'not', 'in', 'a', 'rush', ',', 'this', 'place', 'is', 'a', 'bad', 'idea', '.']\n","original asp tokens:  ['place']\n","original asp indices:  [[10, 20]]\n","1408 :  Unless you are eating in the Pizzeria side of this place, and are not in a rush, this place is a bad idea.\n","original term:  place\n","all start chars:  [51, 86]\n","correct start char:  86\n","text beginning at correct start char:  place is a bad idea.\n","tokens:  ['Unless', 'you', 'are', 'eating', 'in', 'the', 'Pizzeria', 'side', 'of', 'this', 'place', ',', 'and', 'are', 'not', 'in', 'a', 'rush', ',', 'this', 'place', 'is', 'a', 'bad', 'idea', '.']\n","original asp tokens:  ['place']\n","original asp indices:  [[10, 20]]\n","1411 :  I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\n","original term:  portions\n","all start chars:  [32, 270]\n","correct start char:  32\n","text beginning at correct start char:  portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\n","tokens:  ['I', 'must', 'warn', 'the', 'reader', 'that', 'the', 'portions', 'sizes', 'are', 'very', 'small', '(', 'especially', 'the', 'appetizers', ')', ',', 'so', 'if', 'you', 'plan', 'to', 'eat', 'until', 'you', 'are', 'full', 'and', 'do', 'not', 'intend', 'to', 'order', 'the', 'chef', \"'s\", 'special', 'tasting', 'menu', ',', 'prepare', 'to', 'order', 'and', 'pay', 'for', 'an', 'appetizer', '(', '1', 'dish', 'for', 'each', 'person', 'because', 'the', 'portions', 'are', 'not', 'for', 'sharing', ')', ',', 'a', 'main', 'entree', ',', 'and', 'the', 'cold', 'udon', 'at', 'the', 'end', 'of', 'the', 'meal', '.']\n","original asp tokens:  ['portions']\n","original asp indices:  [[7, 57]]\n","1411 :  I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\n","original term:  portions\n","all start chars:  [32, 270]\n","correct start char:  270\n","text beginning at correct start char:  portions are not for sharing), a main entree, and the cold udon at the end of the meal.\n","tokens:  ['I', 'must', 'warn', 'the', 'reader', 'that', 'the', 'portions', 'sizes', 'are', 'very', 'small', '(', 'especially', 'the', 'appetizers', ')', ',', 'so', 'if', 'you', 'plan', 'to', 'eat', 'until', 'you', 'are', 'full', 'and', 'do', 'not', 'intend', 'to', 'order', 'the', 'chef', \"'s\", 'special', 'tasting', 'menu', ',', 'prepare', 'to', 'order', 'and', 'pay', 'for', 'an', 'appetizer', '(', '1', 'dish', 'for', 'each', 'person', 'because', 'the', 'portions', 'are', 'not', 'for', 'sharing', ')', ',', 'a', 'main', 'entree', ',', 'and', 'the', 'cold', 'udon', 'at', 'the', 'end', 'of', 'the', 'meal', '.']\n","original asp tokens:  ['portions']\n","original asp indices:  [[7, 57]]\n","1448 :  Their whitefish salad is excellent--all whitefish with a little mayo.\n","original term:  whitefish\n","all start chars:  [6, 40]\n","correct start char:  40\n","text beginning at correct start char:  whitefish with a little mayo.\n","tokens:  ['Their', 'whitefish', 'salad', 'is', 'excellent', '--', 'all', 'whitefish', 'with', 'a', 'little', 'mayo', '.']\n","original asp tokens:  ['whitefish']\n","original asp indices:  [[1, 7]]\n","1450 :  The chicken parm was edible but had canned tomato sauce and boxed pasta and the chicken with portobello mushrooms consisted of dry, inedible chicken with terrible sauce.\n","original term:  chicken\n","all start chars:  [4, 80, 141]\n","correct start char:  141\n","text beginning at correct start char:  chicken with terrible sauce.\n","tokens:  ['The', 'chicken', 'parm', 'was', 'edible', 'but', 'had', 'canned', 'tomato', 'sauce', 'and', 'boxed', 'pasta', 'and', 'the', 'chicken', 'with', 'portobello', 'mushrooms', 'consisted', 'of', 'dry', ',', 'inedible', 'chicken', 'with', 'terrible', 'sauce', '.']\n","original asp tokens:  ['chicken']\n","original asp indices:  [[1, 15, 24]]\n","1450 :  The chicken parm was edible but had canned tomato sauce and boxed pasta and the chicken with portobello mushrooms consisted of dry, inedible chicken with terrible sauce.\n","original term:  sauce\n","all start chars:  [50, 163]\n","correct start char:  163\n","text beginning at correct start char:  sauce.\n","tokens:  ['The', 'chicken', 'parm', 'was', 'edible', 'but', 'had', 'canned', 'tomato', 'sauce', 'and', 'boxed', 'pasta', 'and', 'the', 'chicken', 'with', 'portobello', 'mushrooms', 'consisted', 'of', 'dry', ',', 'inedible', 'chicken', 'with', 'terrible', 'sauce', '.']\n","original asp tokens:  ['sauce']\n","original asp indices:  [[9, 27]]\n","1472 :  No food snobs allowed, this place is for people who appreciate good food.\n","original term:  food\n","all start chars:  [3, 68]\n","correct start char:  3\n","text beginning at correct start char:  food snobs allowed, this place is for people who appreciate good food.\n","tokens:  ['No', 'food', 'snobs', 'allowed', ',', 'this', 'place', 'is', 'for', 'people', 'who', 'appreciate', 'good', 'food', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 13]]\n","1472 :  No food snobs allowed, this place is for people who appreciate good food.\n","original term:  food\n","all start chars:  [3, 68]\n","correct start char:  68\n","text beginning at correct start char:  food.\n","tokens:  ['No', 'food', 'snobs', 'allowed', ',', 'this', 'place', 'is', 'for', 'people', 'who', 'appreciate', 'good', 'food', '.']\n","original asp tokens:  ['food']\n","original asp indices:  [[1, 13]]\n","1498 :  Monday nights are a bargain at the $28 prix fix - this includes a three course meal plus *three* glasses of wine paired with each course.\n","original term:  course\n","all start chars:  [72, 130]\n","correct start char:  130\n","text beginning at correct start char:  course.\n","tokens:  ['Monday', 'nights', 'are', 'a', 'bargain', 'at', 'the', '$', '28', 'prix', 'fix', '-', 'this', 'includes', 'a', 'three', 'course', 'meal', 'plus', '*', 'three', '*', 'glasses', 'of', 'wine', 'paired', 'with', 'each', 'course', '.']\n","original asp tokens:  ['course']\n","original asp indices:  [[16, 28]]\n","1513 :  The decor in this place is very diner-ish and the kind of place you expect in the East Village - not romantic, just simple, small and sparse.\n","original term:  place\n","all start chars:  [18, 58]\n","correct start char:  58\n","text beginning at correct start char:  place you expect in the East Village - not romantic, just simple, small and sparse.\n","tokens:  ['The', 'decor', 'in', 'this', 'place', 'is', 'very', 'diner-ish', 'and', 'the', 'kind', 'of', 'place', 'you', 'expect', 'in', 'the', 'East', 'Village', '-', 'not', 'romantic', ',', 'just', 'simple', ',', 'small', 'and', 'sparse', '.']\n","original asp tokens:  ['place']\n","original asp indices:  [[4, 12]]\n","Tokenization Error in line  1573 !\n","0 We\n","1 all\n","2 ate\n","3 pasta\n","4 entre'es\n","5 ,\n","6 which\n","7 were\n","8 great\n","9 .\n","aspect term:  pasta entre'es\n","original asp tokens:  ['pasta', 'entre', \"'es\"]\n","start position?3\n","end position?4\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 26, 'to': 26}}, \"We all ate pasta entre'es, which were great.\": {\"pasta entre'es\": {'from': 3, 'to': 4}}}\n","Final aspect tokens:  ['pasta', \"entre'es\"]\n","1812 :  And their prices are very high - they actually think that they can get away with charging such prices for such terrible food and service!\n","original term:  prices\n","all start chars:  [10, 95]\n","correct start char:  10\n","text beginning at correct start char:  prices are very high - they actually think that they can get away with charging such prices for such terrible food and service!\n","tokens:  ['And', 'their', 'prices', 'are', 'very', 'high', '-', 'they', 'actually', 'think', 'that', 'they', 'can', 'get', 'away', 'with', 'charging', 'such', 'prices', 'for', 'such', 'terrible', 'food', 'and', 'service', '!']\n","original asp tokens:  ['prices']\n","original asp indices:  [[2, 18]]\n","1812 :  And their prices are very high - they actually think that they can get away with charging such prices for such terrible food and service!\n","original term:  prices\n","all start chars:  [10, 95]\n","correct start char:  95\n","text beginning at correct start char:  prices for such terrible food and service!\n","tokens:  ['And', 'their', 'prices', 'are', 'very', 'high', '-', 'they', 'actually', 'think', 'that', 'they', 'can', 'get', 'away', 'with', 'charging', 'such', 'prices', 'for', 'such', 'terrible', 'food', 'and', 'service', '!']\n","original asp tokens:  ['prices']\n","original asp indices:  [[2, 18]]\n","1868 :  While most people can attest to spending over $50 on drinks in New York bars and hardly feeling a thing, the drinks here are plentiful and unique.\n","original term:  drinks\n","all start chars:  [53, 109]\n","correct start char:  53\n","text beginning at correct start char:  drinks in New York bars and hardly feeling a thing, the drinks here are plentiful and unique.\n","tokens:  ['While', 'most', 'people', 'can', 'attest', 'to', 'spending', 'over', '$', '50', 'on', 'drinks', 'in', 'New', 'York', 'bars', 'and', 'hardly', 'feeling', 'a', 'thing', ',', 'the', 'drinks', 'here', 'are', 'plentiful', 'and', 'unique', '.']\n","original asp tokens:  ['drinks']\n","original asp indices:  [[11, 23]]\n","1868 :  While most people can attest to spending over $50 on drinks in New York bars and hardly feeling a thing, the drinks here are plentiful and unique.\n","original term:  drinks\n","all start chars:  [53, 109]\n","correct start char:  109\n","text beginning at correct start char:  drinks here are plentiful and unique.\n","tokens:  ['While', 'most', 'people', 'can', 'attest', 'to', 'spending', 'over', '$', '50', 'on', 'drinks', 'in', 'New', 'York', 'bars', 'and', 'hardly', 'feeling', 'a', 'thing', ',', 'the', 'drinks', 'here', 'are', 'plentiful', 'and', 'unique', '.']\n","original asp tokens:  ['drinks']\n","original asp indices:  [[11, 23]]\n","Tokenization Error in line  1914 !\n","0 Do\n","1 n't\n","2 dine\n","3 at\n","4 Tamarind\n","5 for\n","6 the\n","7 vegetarian\n","8 dishes\n","9 ,\n","10 they\n","11 are\n","12 simply\n","13 not\n","14 up\n","15 to\n","16 par\n","17 with\n","18 the\n","19 non-veg\n","20 selections\n","21 .\n","aspect term:  non-veg selections\n","original asp tokens:  ['non', '-', 'veg', 'selections']\n","start position?19\n","end position?20\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 26, 'to': 26}}, \"We all ate pasta entre'es, which were great.\": {\"pasta entre'es\": {'from': 3, 'to': 4}}, \"Don't dine at Tamarind for the vegetarian dishes, they are simply not up to par with the non-veg selections.\": {'non-veg selections': {'from': 19, 'to': 20}}}\n","Final aspect tokens:  ['non-veg', 'selections']\n","1917 :  I've had to wait only a few times during lunch but this place is definitely worth the wait.\n","original term:  wait\n","all start chars:  [12, 86]\n","correct start char:  86\n","text beginning at correct start char:  wait.\n","tokens:  ['I', \"'ve\", 'had', 'to', 'wait', 'only', 'a', 'few', 'times', 'during', 'lunch', 'but', 'this', 'place', 'is', 'definitely', 'worth', 'the', 'wait', '.']\n","original asp tokens:  ['wait']\n","original asp indices:  [[4, 18]]\n","1919 :  Delicious food, excellent service, and a pretty atmosphere make this a great choice for dinner and the $5.99 lunch buffet makes it an even better choice for lunch!\n","original term:  lunch\n","all start chars:  [109, 157]\n","correct start char:  157\n","text beginning at correct start char:  lunch!\n","tokens:  ['Delicious', 'food', ',', 'excellent', 'service', ',', 'and', 'a', 'pretty', 'atmosphere', 'make', 'this', 'a', 'great', 'choice', 'for', 'dinner', 'and', 'the', '$', '5.99', 'lunch', 'buffet', 'makes', 'it', 'an', 'even', 'better', 'choice', 'for', 'lunch', '!']\n","original asp tokens:  ['lunch']\n","original asp indices:  [[21, 30]]\n","1944 :  I've had the chicken with garlic sauce, chicken with black bean sauce, and hunan chicken.\n","original term:  chicken with garlic sauce\n","all start chars:  [13, 40, 81]\n","correct start char:  13\n","text beginning at correct start char:  chicken with garlic sauce, chicken with black bean sauce, and hunan chicken.\n","tokens:  ['I', \"'ve\", 'had', 'the', 'chicken', 'with', 'garlic', 'sauce', ',', 'chicken', 'with', 'black', 'bean', 'sauce', ',', 'and', 'hunan', 'chicken', '.']\n","original asp tokens:  ['chicken', 'with', 'garlic', 'sauce']\n","original asp indices:  [[4, 9, 17], [5, 10], [6], [7, 13]]\n","1944 :  I've had the chicken with garlic sauce, chicken with black bean sauce, and hunan chicken.\n","original term:  chicken with black bean sauce\n","all start chars:  [13, 40, 81]\n","correct start char:  40\n","text beginning at correct start char:  chicken with black bean sauce, and hunan chicken.\n","tokens:  ['I', \"'ve\", 'had', 'the', 'chicken', 'with', 'garlic', 'sauce', ',', 'chicken', 'with', 'black', 'bean', 'sauce', ',', 'and', 'hunan', 'chicken', '.']\n","original asp tokens:  ['chicken', 'with', 'black', 'bean', 'sauce']\n","original asp indices:  [[4, 9, 17], [5, 10], [11], [12], [7, 13]]\n","Tokenization Error in line  1944 !\n","0 I\n","1 've\n","2 had\n","3 the\n","4 chicken\n","5 with\n","6 garlic\n","7 sauce\n","8 ,\n","9 chicken\n","10 with\n","11 black\n","12 bean\n","13 sauce\n","14 ,\n","15 and\n","16 hunan\n","17 chicken\n","18 .\n","aspect term:  chicken with black bean sauce\n","original asp tokens:  ['chicken', 'with', 'black', 'bean', 'sauce']\n","start position?9\n","end position?13\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 26, 'to': 26}}, \"We all ate pasta entre'es, which were great.\": {\"pasta entre'es\": {'from': 3, 'to': 4}}, \"Don't dine at Tamarind for the vegetarian dishes, they are simply not up to par with the non-veg selections.\": {'non-veg selections': {'from': 19, 'to': 20}}, \"I've had the chicken with garlic sauce, chicken with black bean sauce, and hunan chicken.\": {'chicken with black bean sauce': {'from': 9, 'to': 13}}}\n","Final aspect tokens:  ['chicken', 'with', 'black', 'bean', 'sauce']\n","213 :  When he finally did, he was unable to make a gin and tonic -- couldn't find tonic.\n","original term:  tonic\n","all start chars:  [53, 76]\n","correct start char:  76\n","text beginning at correct start char:  tonic.\n","tokens:  ['When', 'he', 'finally', 'did', ',', 'he', 'was', 'unable', 'to', 'make', 'a', 'gin', 'and', 'tonic', '--', 'could', \"n't\", 'find', 'tonic', '.']\n","original asp tokens:  ['tonic']\n","original asp indices:  [[13, 18]]\n","359 :  This is one great place to eat pizza more out but not a good place for take-out pizza.\n","original term:  pizza\n","all start chars:  [31, 80]\n","correct start char:  31\n","text beginning at correct start char:  pizza more out but not a good place for take-out pizza.\n","tokens:  ['This', 'is', 'one', 'great', 'place', 'to', 'eat', 'pizza', 'more', 'out', 'but', 'not', 'a', 'good', 'place', 'for', 'take', '-', 'out', 'pizza', '.']\n","original asp tokens:  ['pizza']\n","original asp indices:  [[7, 19]]\n","451 :  - the bread at the beginning is super tasty and makes you want more - the pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\n","original term:  pizza\n","all start chars:  [74, 167, 230]\n","correct start char:  74\n","text beginning at correct start char:  pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\n","tokens:  ['-', 'the', 'bread', 'at', 'the', 'beginning', 'is', 'super', 'tasty', 'and', 'makes', 'you', 'want', 'more', '-', 'the', 'pizza', 'is', 'delicious', 'and', 'comes', 'in', 'personal', 'sizes', ',', 'however', 'be', 'warned', 'that', 'the', 'Peter', \"'s\", 'Favourite', 'pizza', 'with', 'prosciutto', 'and', 'baby', 'arugula', 'is', 'actually', 'a', 'margarite', 'pizza', 'with', 'cold', 'prosciutto', 'and', 'baby', 'arugula', 'on', 'top', ',', 'like', 'a', 'salad', '.']\n","original asp tokens:  ['pizza']\n","original asp indices:  [[16, 33, 43]]\n","489 :  The table service could have been a little more attentive but as someone who also works in the service industry, I understood they were busy.\n","original term:  service\n","all start chars:  [10, 95]\n","correct start char:  95\n","text beginning at correct start char:  service industry, I understood they were busy.\n","tokens:  ['The', 'table', 'service', 'could', 'have', 'been', 'a', 'little', 'more', 'attentive', 'but', 'as', 'someone', 'who', 'also', 'works', 'in', 'the', 'service', 'industry', ',', 'I', 'understood', 'they', 'were', 'busy', '.']\n","original asp tokens:  ['service']\n","original asp indices:  [[2, 18]]\n","622 :  There was a long wait for a table outside, but it was a little too hot in the sun anyway so our insde table was very nice.\n","original term:  table\n","all start chars:  [28, 102]\n","correct start char:  28\n","text beginning at correct start char:  table outside, but it was a little too hot in the sun anyway so our insde table was very nice.\n","tokens:  ['There', 'was', 'a', 'long', 'wait', 'for', 'a', 'table', 'outside', ',', 'but', 'it', 'was', 'a', 'little', 'too', 'hot', 'in', 'the', 'sun', 'anyway', 'so', 'our', 'insde', 'table', 'was', 'very', 'nice', '.']\n","original asp tokens:  ['table']\n","original asp indices:  [[7, 24]]\n","Tokenization Error in line  657 !\n","0 The\n","1 in\n","2 -house\n","3 lady\n","4 DJ\n","5 on\n","6 Saturday\n","7 nights\n","8 has\n","9 outrageously\n","10 good\n","11 taste\n","12 in\n","13 music\n","14 ,\n","15 and\n","16 moreover\n","17 ,\n","18 takes\n","19 requests\n","20 .\n","aspect term:  in-house lady DJ\n","original asp tokens:  ['in-house', 'lady', 'DJ']\n","start position?1\n","end position?4\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 26, 'to': 26}}, \"We all ate pasta entre'es, which were great.\": {\"pasta entre'es\": {'from': 3, 'to': 4}}, \"Don't dine at Tamarind for the vegetarian dishes, they are simply not up to par with the non-veg selections.\": {'non-veg selections': {'from': 19, 'to': 20}}, \"I've had the chicken with garlic sauce, chicken with black bean sauce, and hunan chicken.\": {'chicken with black bean sauce': {'from': 9, 'to': 13}}, 'The in-house lady DJ on Saturday nights has outrageously good taste in music, and moreover, takes requests.': {'in-house lady DJ': {'from': 1, 'to': 4}}}\n","Final aspect tokens:  ['in', '-house', 'lady', 'DJ']\n","1159 :  Only drawback - they won't toast your bagel, and they don't make eggs for the bagel.\n","original term:  bagel\n","all start chars:  [38, 78]\n","correct start char:  38\n","text beginning at correct start char:  bagel, and they don't make eggs for the bagel.\n","tokens:  ['Only', 'drawback', '-', 'they', 'wo', \"n't\", 'toast', 'your', 'bagel', ',', 'and', 'they', 'do', \"n't\", 'make', 'eggs', 'for', 'the', 'bagel', '.']\n","original asp tokens:  ['bagel']\n","original asp indices:  [[8, 18]]\n","1159 :  Only drawback - they won't toast your bagel, and they don't make eggs for the bagel.\n","original term:  bagel\n","all start chars:  [38, 78]\n","correct start char:  78\n","text beginning at correct start char:  bagel.\n","tokens:  ['Only', 'drawback', '-', 'they', 'wo', \"n't\", 'toast', 'your', 'bagel', ',', 'and', 'they', 'do', \"n't\", 'make', 'eggs', 'for', 'the', 'bagel', '.']\n","original asp tokens:  ['bagel']\n","original asp indices:  [[8, 18]]\n","Tokenization Error in line  1168 !\n","0 Try\n","1 the\n","2 Pad\n","3 Se\n","4 -\n","5 Ew\n","6 or\n","7 Chicken\n","8 with\n","9 Cashew\n","10 Nuts\n","11 for\n","12 a\n","13 memorable\n","14 and\n","15 repeatable\n","16 experience\n","17 .\n","aspect term:  Pad Se-Ew\n","original asp tokens:  ['Pad', 'Se-', 'Ew']\n","start position?2\n","end position?5\n","{'The atmosphere was crowded but it was a great bistro-type vibe.': {'bistro-type vibe': {'from': 9, 'to': 11}}, 'We were still sitting at the bar while we drank the sangria, but facing away from the bar when we turned back around, the $2 was gone the people next to us said the bartender took it.': {'bar': {'from': 18, 'to': 18}}, \"It costs $2 extra to turn a regular roll into an inside-out roll, but the roll more than triples in size, and that's not just from the rice.\": {'roll': {'from': 15, 'to': 15}}, 'Food-awesome.': {'Food': {'from': 0, 'to': 0}}, 'So much more than the usual bar food, go there to enjoy the menu while sampling one of their hand-crafted beers.': {'hand-crafted beers': {'from': 20, 'to': 23}}, \"Fluke sashimi drizzled with jalapeno-lime olive oil, the fruit of the oil nicely highlighting the fish's sweetness.\": {'jalapeno-lime olive oil': {'from': 4, 'to': 7}}, 'Although the tables may be closely situated, the candle-light, food-quality and service overcompensate.': {'food-quality': {'from': 13, 'to': 15}}, \"The pesto pizza was excellent, thin-crust pizza with a nice amount of spicy Italian cheese that I'd never heard of before.\": {'thin-crust pizza': {'from': 6, 'to': 8}}, \"The food can get pricey but the prixe fixe tasting menu is the greatest food for a good price and they cater the food to any food allergies or food you don't like.\": {'food': {'from': 26, 'to': 26}}, \"We all ate pasta entre'es, which were great.\": {\"pasta entre'es\": {'from': 3, 'to': 4}}, \"Don't dine at Tamarind for the vegetarian dishes, they are simply not up to par with the non-veg selections.\": {'non-veg selections': {'from': 19, 'to': 20}}, \"I've had the chicken with garlic sauce, chicken with black bean sauce, and hunan chicken.\": {'chicken with black bean sauce': {'from': 9, 'to': 13}}, 'The in-house lady DJ on Saturday nights has outrageously good taste in music, and moreover, takes requests.': {'in-house lady DJ': {'from': 1, 'to': 4}}, 'Try the Pad Se-Ew or Chicken with Cashew Nuts for a memorable and repeatable experience.': {'Pad Se-Ew': {'from': 2, 'to': 5}}}\n","Final aspect tokens:  ['Pad', 'Se', '-', 'Ew']\n","1280 :  Where tanks in other Chinatown restaurants display a lurking myriad of sad-looking marine life in their murky waters, the tanks at Ping's are clear as glass with healthy-looking creatures who do not yet know that they will be part of some dim sum lover's brunch.\n","original term:  tanks\n","all start chars:  [6, 122]\n","correct start char:  6\n","text beginning at correct start char:  tanks in other Chinatown restaurants display a lurking myriad of sad-looking marine life in their murky waters, the tanks at Ping's are clear as glass with healthy-looking creatures who do not yet know that they will be part of some dim sum lover's brunch.\n","tokens:  ['Where', 'tanks', 'in', 'other', 'Chinatown', 'restaurants', 'display', 'a', 'lurking', 'myriad', 'of', 'sad-looking', 'marine', 'life', 'in', 'their', 'murky', 'waters', ',', 'the', 'tanks', 'at', 'Ping', \"'s\", 'are', 'clear', 'as', 'glass', 'with', 'healthy', '-', 'looking', 'creatures', 'who', 'do', 'not', 'yet', 'know', 'that', 'they', 'will', 'be', 'part', 'of', 'some', 'dim', 'sum', 'lover', \"'s\", 'brunch', '.']\n","original asp tokens:  ['tanks']\n","original asp indices:  [[1, 20]]\n","1280 :  Where tanks in other Chinatown restaurants display a lurking myriad of sad-looking marine life in their murky waters, the tanks at Ping's are clear as glass with healthy-looking creatures who do not yet know that they will be part of some dim sum lover's brunch.\n","original term:  tanks\n","all start chars:  [6, 122]\n","correct start char:  122\n","text beginning at correct start char:  tanks at Ping's are clear as glass with healthy-looking creatures who do not yet know that they will be part of some dim sum lover's brunch.\n","tokens:  ['Where', 'tanks', 'in', 'other', 'Chinatown', 'restaurants', 'display', 'a', 'lurking', 'myriad', 'of', 'sad-looking', 'marine', 'life', 'in', 'their', 'murky', 'waters', ',', 'the', 'tanks', 'at', 'Ping', \"'s\", 'are', 'clear', 'as', 'glass', 'with', 'healthy', '-', 'looking', 'creatures', 'who', 'do', 'not', 'yet', 'know', 'that', 'they', 'will', 'be', 'part', 'of', 'some', 'dim', 'sum', 'lover', \"'s\", 'brunch', '.']\n","original asp tokens:  ['tanks']\n","original asp indices:  [[1, 20]]\n","1289 :  We ordered the chicken casserole, but what we got were a few small pieces of chicken, all dark meat and on the bone.\n","original term:  chicken\n","all start chars:  [15, 77]\n","correct start char:  77\n","text beginning at correct start char:  chicken, all dark meat and on the bone.\n","tokens:  ['We', 'ordered', 'the', 'chicken', 'casserole', ',', 'but', 'what', 'we', 'got', 'were', 'a', 'few', 'small', 'pieces', 'of', 'chicken', ',', 'all', 'dark', 'meat', 'and', 'on', 'the', 'bone', '.']\n","original asp tokens:  ['chicken']\n","original asp indices:  [[3, 16]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A9j2SYYxWT1y"},"source":["## in case of reproducing the dataset"]},{"cell_type":"code","metadata":{"id":"LbLhvcZ_Yag5"},"source":["def json_maker(df, manual_pos):\n","   \n","    new_data = []\n","\n","    for ii in df.index:\n","        \n","        new_dict = {}\n","        text = df.loc[ii,\"text\"]\n","\n","        tokens = [token.text for sentence in nlp(text).sentences for token in sentence.tokens]\n","        new_dict[\"token\"] = tokens\n","\n","        new_dict[\"pos\"] = [word.xpos for sentence in nlp(text).sentences for word in sentence.words]\n","        new_dict[\"head\"] = [str(word.head) for sentence in nlp(text).sentences for word in sentence.words]\n","        new_dict[\"deprel\"] = [word.deprel for sentence in nlp(text).sentences for word in sentence.words]\n","        \n","        new_dict[\"aspects\"] = []\n","        for xx in range(1,aspect_number):         \n","            if df.loc[ii,\"aspect_term_\"+str(xx)] != None:\n","                asp_dict = {}   \n","                term = df.loc[ii,\"aspect_term_\"+str(xx)]\n","                asp_dict[\"term\"] = term\n","                asp_dict[\"polarity\"] = df.loc[ii,\"aspect_polarity_\"+str(xx)]\n","\n","                # construct aspect position on token level\n","                asp_toks = [token.text for sentence in nlp(term).sentences for token in sentence.tokens]\n","                asp_ind = [list(locate(tokens, lambda a: a == term)) for term in asp_toks]\n","\n","                # for aspects appearing only once in text, take the correct position\n","                # otherwise set to None\n","                if len(asp_ind[0]) == 1:\n","                    from_index = asp_ind[0][0]\n","                else:\n","                    from_index = None\n","                if len(asp_ind[-1]) == 1:\n","                    to_index = asp_ind[-1][0] \n","                else: \n","                    to_index = None\n","\n","                # if both start and end pos are unknown, \n","                # e.g. for single-word aspects, \n","                # take character positions for help\n","                if from_index == None and to_index == None and len(asp_ind[0]) != 0:\n","\n","                    all_char_from = [i for i in range(len(text)) if text.startswith(asp_toks[0], i)]\n","                    corr_char_from = int(df.loc[ii, \"aspect_from_\"+str(xx)])\n","\n","                    if corr_char_from == max(all_char_from):\n","                        from_index = asp_ind[0][-1]\n","                    elif corr_char_from == min(all_char_from):\n","                        from_index = asp_ind[0][0]\n","\n","                # in case of missing start/end positions,\n","                # try to find \"to\"/\"from\" using aspect token number as distance\n","                if from_index == None and to_index != None:\n","                    from_index = to_index - len(asp_toks) +1\n","                if to_index == None and from_index != None:\n","                    to_index = from_index + len(asp_toks) -1\n","\n","                # correct tokenization errors in aspect term tokenization\n","                if from_index == None or to_index == None or asp_toks != tokens[from_index:to_index+1]:\n","                    if text in manual_pos.keys() and term in manual_pos[text].keys():\n","                        from_index = manual_pos[text][term][\"from\"]\n","                        to_index = manual_pos[text][term][\"to\"]\n","\n","                asp_dict[\"from\"] = from_index\n","                asp_dict[\"to\"] = to_index + 1\n","\n","                new_dict[\"aspects\"] += [asp_dict]\n","        \n","        new_data += [new_dict]\n","\n","    return new_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQPJT5UUU8DZ"},"source":["pos_obj = open(aspect_path+\"semeval_rest_train.json\")\n","loaded_pos = json.load(pos_obj)\n","\n","for key,val in data_dict.items():\n","\n","    json_data = json_maker(val, loaded_pos)\n","\n","    with open(output_path+key+\".json\",\"w\") as f:\n","        json.dump(json_data, f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aeHXUSmyaRfA"},"source":["# Create LCF-ATEPCdat"]},{"cell_type":"code","metadata":{"id":"si0ea14Q4PVZ"},"source":["def pol_to_no_shifted(sentiment):\n","  \n","    if sentiment == \"positive\":\n","        pol = 2\n","    elif sentiment == \"negative\":\n","        pol = 0\n","    elif sentiment == \"neutral\":\n","        pol = 1\n","\n","    return str(pol)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7z0s04TbaVXo"},"source":["def dat_maker(df):\n","    \n","    data_lines = []\n","\n","    for line in df.index:\n","\n","        text = df.loc[line,\"text\"]\n","        tokens = nltk.word_tokenize(text)\n","\n","        # correct tokens\n","        for no,tok in enumerate(tokens):\n","            if tok[-1:] == \"-\" and len(tok)>2:\n","                tokens[no] = tok[:-1]\n","            if tok[:1] == \"'\" and len(tok)>3:\n","                tokens[no] = tok[1:]\n","            if tok in [\"'\",\"(\",\")\"]:\n","                tokens.remove(tok)\n","\n","        # create aspect-polarity dict\n","        asp_sent_dict = {}\n","        max_asp_len = 0\n","        for col in range(len(asp_cols)):\n","            aspect = df.loc[line,asp_cols[col]]\n","            if aspect != None:\n","                asp_sent_dict[aspect] = pol_to_no_shifted(df.loc[line,pol_cols[col]])\n","                if len(aspect.split()) > max_asp_len:\n","                    max_asp_len = len(aspect.split())\n","\n","        label = \"\"\n","        # check for one-word-aspects\n","        for tok in tokens:\n","            if tok in asp_sent_dict.keys():\n","                label += tok + \" B-ASP -1\\n\"\n","            else:\n","                label += tok + \" O -1\\n\"\n","\n","        # check for multi-word-aspects\n","        for ii in range(2,max_asp_len+1):\n","            for no,tok in enumerate(tokens):\n","                new_tok = \" \".join(tokens[no:no+ii])\n","                if new_tok not in tokens and new_tok in asp_sent_dict.keys():\n","                    label = label.replace(tokens[no]+\" O -1\",tokens[no]+\" B-ASP -1\")\n","                    for xx in range(1,ii):\n","                        label = label.replace(tokens[no+xx]+\" O -1\",tokens[no+xx]+\" I-ASP -1\")\n","\n","        # create duplicates of review in case of more than one aspect\n","        for key, val in asp_sent_dict.items():\n","            if key in tokens:\n","                new_label = label.replace(key+\" B-ASP -1\", key+\" B-ASP \"+val)\n","                data_lines += [new_label]\n","                data_lines += [\"\\n\"]\n","            else:\n","                for ii in range(2,max_asp_len+1):\n","                    for no,tok in enumerate(tokens):\n","                        new_tok = \" \".join(tokens[no:no+ii])\n","                        if new_tok == key:\n","                            new_label = label.replace(tokens[no]+\" B-ASP -1\",tokens[no]+\" B-ASP \"+val)\n","                            for xx in range(1,ii):\n","                                new_label = new_label.replace(tokens[no+xx]+\" I-ASP -1\",tokens[no+xx]+\" I-ASP \"+val)\n","\n","                            data_lines += [new_label]\n","                            data_lines += [\"\\n\"]\n","\n","    return data_lines"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n87vqlsKa36r"},"source":["for key,val in data_dict.items():\n","\n","    dat_data = dat_maker(val)\n","\n","    with open(output_path+key+\".dat\",\"w\") as f:\n","        f.write(''.join(dat_data))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zccA_AJz1ZW4"},"source":["# Create GRACEtxt"]},{"cell_type":"code","metadata":{"id":"Jht_ESNPhmOY"},"source":["asp_cols = [\"aspect_term_\"+str(ii) for ii in range(1,aspect_number)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORfnB8CS6qjN"},"source":["import nltk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ce4Aqwxh7VGF","executionInfo":{"status":"ok","timestamp":1621532045297,"user_tz":-120,"elapsed":331,"user":{"displayName":"Elisabeth Lebmeier","photoUrl":"","userId":"15954454745832712963"}},"outputId":"7e05c899-546e-4aa1-a8c1-19a5e4cb297c"},"source":["nltk.download('averaged_perceptron_tagger')\n","nltk.download('conll2000')\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/conll2000.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"al0gF6NL1cdd"},"source":["Create chunks and pos tags. Source: https://towardsdatascience.com/chunking-in-nlp-decoded-b4a71b2b4e24\n"]},{"cell_type":"code","metadata":{"id":"z-KWOrnf_5hn"},"source":["from nltk.tag import UnigramTagger, BigramTagger\n","from nltk.chunk import ChunkParserI\n","from nltk.chunk.util import tree2conlltags, conlltags2tree\n","from nltk.corpus import conll2000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mL0s_64z7oaF"},"source":["def conll_tag_chunks(chunk_sents):\n","    tagged_sents = [tree2conlltags(tree) for tree in chunk_sents]\n","    return [[(t, c) for (w, t, c) in sent] for sent in tagged_sents]\n","    \n","def combined_tagger(train_data, taggers, backoff=None):\n","    for tagger in taggers:\n","        backoff = tagger(train_data, backoff=backoff)\n","    return backoff\n","\n","class NGramTagChunker(ChunkParserI):\n","\n","    def __init__(self,train_sentences,tagger_classes=[UnigramTagger,BigramTagger]):\n","        train_sent_tags=conll_tag_chunks(train_sentences)\n","        self.chunk_tagger=combined_tagger(train_sent_tags,tagger_classes)\n","    \n","    def parse(self,tagged_sentence):\n","        if not tagged_sentence:\n","            return None\n","        pos_tags=[tag for word, tag in tagged_sentence]\n","        chunk_pos_tags=self.chunk_tagger.tag(pos_tags)\n","        chunk_tags=[chunk_tag for (pos_tag,chunk_tag) in chunk_pos_tags]\n","        wpc_tags=[(word,pos_tag,chunk_tag) for ((word,pos_tag),chunk_tag) in zip(tagged_sentence,chunk_tags)]\n","        return conlltags2tree(wpc_tags)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XBO64Z0ANbJ"},"source":["data = conll2000.chunked_sents()\n","ntc = NGramTagChunker(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mUp02s4XBOY3"},"source":["Convert tags into BIOES scheme. Source: https://gist.github.com/allanj/5ad206f7f4645c0269b68fb2065712f4"]},{"cell_type":"code","metadata":{"id":"ZEtfTq5dC5Za"},"source":["def iob_iobes(tags):\n","    \"\"\"\n","    IOB2 (BIO) -> IOBES\n","    \"\"\"\n","    new_tags = []\n","    for i, tag in enumerate(tags):\n","        if tag == 'O':\n","            new_tags.append(tag)\n","        elif tag.split('-')[0] == 'B':\n","            if i + 1 != len(tags) and \\\n","                    tags[i + 1].split('-')[0] == 'I':\n","                new_tags.append(tag)\n","            else:\n","                new_tags.append(tag.replace('B-', 'S-'))\n","        elif tag.split('-')[0] == 'I':\n","            if i + 1 < len(tags) and \\\n","                    tags[i + 1].split('-')[0] == 'I':\n","                new_tags.append(tag)\n","            else:\n","                new_tags.append(tag.replace('I-', 'E-'))\n","        else:\n","            raise Exception('Invalid IOB format!')\n","    return new_tags"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQAlwhpqRwWS"},"source":["def grace_txt_maker(df):\n","    \n","    data_lines = []\n","\n","    for line in df.index:\n","\n","        text = df.text[line]\n","        tokens = nltk.word_tokenize(text)\n","\n","        # correct tokens\n","        for no,tok in enumerate(tokens):\n","            if tok[-1:] == \"-\" and len(tok)>2:\n","                tokens[no] = tok[:-1]\n","            if tok[:1] == \"'\" and len(tok)>3:\n","                tokens[no] = tok[1:]\n","            if tok in [\"'\",\"(\",\")\"]:\n","                tokens.remove(tok)\n","\n","        # create pos tags\n","        pos_tags = nltk.pos_tag(tokens)\n","\n","        # create chunk/phrase tags\n","        full_tags = tree2conlltags(ntc.parse(pos_tags))\n","        chunks_list = [full_tags[ii][2] for ii in range(len(full_tags))]\n","        new_chunks = iob_iobes(chunks_list)\n","\n","        # create aspect-polarity dict\n","        asp_sent_dict = {}\n","        max_asp_len = 0\n","        for col in range(len(asp_cols)):\n","            aspect = df.loc[line,asp_cols[col]]\n","            if aspect != None:\n","                asp_sent_dict[aspect] = df.loc[line,pol_cols[col]].upper()\n","                if len(aspect.split()) > max_asp_len:\n","                    max_asp_len = len(aspect.split())\n","\n","        label = \"\"\n","        # check for one-word-aspects\n","        for pos,tok in enumerate(tokens):\n","            label += tok + \" \" + pos_tags[pos][1] + \" \" + new_chunks[pos]\n","            if tok in asp_sent_dict.keys():\n","                label +=  \" B_AP \" + asp_sent_dict[tok] + \" B_AP+\" + asp_sent_dict[tok] + \"\\n\"\n","            else:\n","                label += \" O O O \\n\"\n","\n","        # check for multi-word-aspects\n","        for ii in range(2,max_asp_len+1):\n","            for no,tok in enumerate(tokens):\n","                new_tok = \" \".join(tokens[no:no+ii])\n","                if new_tok not in tokens and new_tok in asp_sent_dict.keys():\n","                    new_pol = asp_sent_dict[new_tok]\n","                    label = label.replace(tokens[no]+ \" \" + pos_tags[no][1] + \" \" + new_chunks[no] + \" O O O \\n\",\n","                                          tokens[no]+ \" \" + pos_tags[no][1] + \" \" + new_chunks[no] + \" B_AP \" + \\\n","                                          new_pol + \" B_AP+\" + new_pol + \"\\n\")\n","                    for xx in range(1,ii):\n","                        label = label.replace(tokens[no+xx] + \" \" + pos_tags[no+xx][1] + \" \" + new_chunks[no+xx] + \" O O O \\n\",\n","                                          tokens[no+xx]+ \" \" + pos_tags[no+xx][1] + \" \" + new_chunks[no+xx] + \" I_AP \" + \\\n","                                          new_pol + \" I_AP+\" + new_pol + \"\\n\")\n","\n","        data_lines += [label]\n","\n","    return data_lines"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jCIhax6erbg"},"source":["for key,val in data_dict.items():\n","\n","    grace_txt_data = grace_txt_maker(val)\n","\n","    with open(output_path+\"grace_\"+key+\".txt\",\"w\") as f:\n","        f.write('\\n'.join(grace_txt_data))"],"execution_count":null,"outputs":[]}]}